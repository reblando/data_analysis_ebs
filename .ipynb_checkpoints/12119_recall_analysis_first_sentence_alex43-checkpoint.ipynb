{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Sentences Defining Event Boundaries\n",
    "# I: Social Primed Participants\n",
    "# II: Location Primed Participants\n",
    "# IV: Graphing\n",
    "# V: Printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import pickle\n",
    "import seaborn as sb\n",
    "\n",
    "%autosave 5\n",
    "\n",
    "#import Alex-scored free recall sheets for story 43\n",
    "xls43 = pd.ExcelFile('/Users/alexreblando/Documents/Baldassano Lab/43_Alex.xlsx')\n",
    "\n",
    "#get sheet names\n",
    "xls = xlrd.open_workbook(r'/Users/alexreblando/Documents/Baldassano Lab/43_Alex.xlsx', on_demand=True)\n",
    "sheet_names = xls.sheet_names()\n",
    "\n",
    "#import story stats in order to get story lengths\n",
    "pickle_in = open(\"story_stats.pickle\",\"rb\")\n",
    "story_stats = pickle.load(pickle_in)\n",
    "\n",
    "#import story boundaries to get putative event boundaries\n",
    "pickle_in = open(\"story_boundaries.pickle\",\"rb\")\n",
    "story_boundaries = pickle.load(pickle_in)\n",
    "\n",
    "#import subj_schemas matrix so that for each story for each subject you can know if they are\n",
    "#social or location primed\n",
    "pickle_in = open(\"subj_schemas.pickle\",\"rb\")\n",
    "subj_schemas = pickle.load(pickle_in)\n",
    "\n",
    "#Dictionary of scored sheets of individual participants\n",
    "rs_dict = {}\n",
    "\n",
    "for name in sheet_names:\n",
    "    rs_dict[name] = pd.read_excel(xls43, name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Sentences defining event boundaries\n",
    "## Step 1: Social Events\n",
    "## Step 2: Location Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Determining the story sentences that mark the boundaries of each social event\n",
    "soc_event = {}\n",
    "\n",
    "#make the dictionary of all the events\n",
    "for i in range(1,5):\n",
    "    soc_event[i] = np.zeros((1,3))\n",
    "\n",
    "count = 1\n",
    "for j in range(len(story_boundaries['43'])):\n",
    "    if story_boundaries['43'][j, 1] == 1:\n",
    "        if count == 1:\n",
    "            soc_event[count][0,0] = 1\n",
    "            count = 2\n",
    "        else:\n",
    "            soc_event[count-1][0,1] = j\n",
    "            soc_event[count][0,0] = j+1\n",
    "            count += 1\n",
    "        \n",
    "soc_event[4][0,1] = len(story_boundaries['43']) \n",
    "\n",
    "#length of each event\n",
    "for i in range(1,5):\n",
    "    soc_event[i][0,2] = soc_event[i][0,1] - soc_event[i][0,0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Determining the story sentences that define the location events\n",
    "loc_event = {}\n",
    "\n",
    "#make the dictionary of all the events\n",
    "for i in range(1,5):\n",
    "    loc_event[i] = np.zeros((1,3))\n",
    "\n",
    "count = 1\n",
    "for j in range(len(story_boundaries['43'])):\n",
    "    if story_boundaries['43'][j, 0] == 1:\n",
    "        if count == 1:\n",
    "            loc_event[count][0,0] = 1\n",
    "            count = 2\n",
    "        else:\n",
    "            loc_event[count-1][0,1] = j\n",
    "            loc_event[count][0,0] = j+1\n",
    "            count += 1\n",
    "            \n",
    "        \n",
    "loc_event[4][0,1] = len(story_boundaries['43']) \n",
    "\n",
    "#length of each event\n",
    "for i in range(1,5):\n",
    "    loc_event[i][0,2] = loc_event[i][0,1] - loc_event[i][0,0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Social Primed Participants\n",
    "## Step 1: Participant x Story Sentence matrix\n",
    "## Step 2 : Social Event Starts: first sentence recall average for each event\n",
    "## Step 3: Location Events Starts: first sentence recall average for each event\n",
    "## Step 4: Non-event-start sentences\n",
    "## Step 5: Average of all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: make a participant x story sentence matrix with '1' values for sentences that that \n",
    "#participant mentioned in their free recall for social primed participants\n",
    "\n",
    "#find the number of sentences in story 43\n",
    "n_sent = story_stats['43'][3]\n",
    "\n",
    "#the number of social primed participants\n",
    "n_social = (sum( x == 'Social' for x in subj_schemas['43'].values()))\n",
    "\n",
    "#make empty participant x story sentences matrix\n",
    "soc_subj_sent_m = np.zeros((n_social, n_sent))\n",
    "count = 0\n",
    "for name in sheet_names:\n",
    "    if subj_schemas['43'][name] == 'Social':\n",
    "        for i in range(n_sent):\n",
    "            val = np.sum(rs_dict[name][i+1])\n",
    "            if val > 0:\n",
    "                val = 1\n",
    "            soc_subj_sent_m[count, i] = val\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Social Event Starts: first sentence count for each event\n",
    "#output: SP_SE = [avg recall for 1st event, \" second event, \" third event]\n",
    "SP_SE = []\n",
    "\n",
    "for i in range(2,5):\n",
    "    this_column = int(soc_event[i][0,0] - 1)\n",
    "    sum_recall = sum(soc_subj_sent_m[:, this_column])    \n",
    "    avg_recall = sum_recall/n_social\n",
    "    SP_SE.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Location Event Starts: first sentence count for each event\n",
    "#output: SP_LE = [avg recall for 1st event, \" second event, \" third event]\n",
    "SP_LE = []\n",
    "\n",
    "for i in range(2,5):\n",
    "    this_column = int(loc_event[i][0,0] - 1)\n",
    "    sum_recall = sum(soc_subj_sent_m[:, this_column])    \n",
    "    avg_recall = sum_recall/n_social\n",
    "    SP_LE.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Non-event-Start sentences\n",
    "\n",
    "non_start_cols = []\n",
    "for i in range(0, len(story_boundaries['43'])):\n",
    "    tag = 0\n",
    "    for j in range(2,5):\n",
    "        if i == int(soc_event[j][0,0] - 1):\n",
    "            tag += 1\n",
    "        elif i == int(loc_event[j][0,0] - 1):\n",
    "            tag += 1\n",
    "    if tag == 0:\n",
    "        sum_recall = sum(soc_subj_sent_m[:, i])    \n",
    "        avg_recall = sum_recall/n_social\n",
    "        non_start_cols.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Averages of all sentence types\n",
    "#output: SP_avg_all_sents= [social-event-starts, location-event-starts, non-event-starts]\n",
    "\n",
    "SP_avg_all_sents = [statistics.mean(SP_SE), statistics.mean(SP_LE), statistics.mean(non_start_cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Location Primed Participants\n",
    "## Step 1: Participant x Story Sentence matrix\n",
    "## Step 2 : Social Event Starts: first sentence recall average for each event\n",
    "## Step 3: Location Events Starts: first sentence recall average for each event\n",
    "## Step 4: Non-event-start sentences\n",
    "## Step 5: Average of all events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: make a participant x story sentence matrix with '1' values for sentences that that \n",
    "#participant mentioned in their free recall for social primed participants\n",
    "\n",
    "priming_type = 'Location'\n",
    "\n",
    "#find the number of sentences in story 43\n",
    "n_sent = story_stats['43'][3]\n",
    "\n",
    "#the number of social primed participants\n",
    "n_location = (sum( x == priming_type for x in subj_schemas['43'].values()))\n",
    "\n",
    "#make empty participant x story sentences matrix\n",
    "loc_subj_sent_m = np.zeros((n_location, n_sent))\n",
    "count = 0\n",
    "for name in sheet_names:\n",
    "    if subj_schemas['43'][name] == priming_type:\n",
    "        for i in range(n_sent):\n",
    "            val = np.sum(rs_dict[name][i+1])\n",
    "            if val > 0:\n",
    "                val = 1\n",
    "            loc_subj_sent_m[count, i] = val\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Social Event Starts: first sentence count for each event\n",
    "#output: SP_SE = [avg recall for 1st event, \" second event, \" third event]\n",
    "LP_SE = []\n",
    "\n",
    "for i in range(2,5):\n",
    "    this_column = int(soc_event[i][0,0] - 1)\n",
    "    sum_recall = sum(loc_subj_sent_m[:, this_column])    \n",
    "    avg_recall = sum_recall/n_location\n",
    "    LP_SE.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Location Event Starts: first sentence count for each event\n",
    "#output: SP_LE = [avg recall for 1st event, \" second event, \" third event]\n",
    "LP_LE = []\n",
    "\n",
    "for i in range(2,5):\n",
    "    this_column = int(loc_event[i][0,0] - 1)\n",
    "    sum_recall = sum(loc_subj_sent_m[:, this_column])    \n",
    "    avg_recall = sum_recall/n_location\n",
    "    LP_LE.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Non-event-Start sentences\n",
    "\n",
    "LP_non_start_cols = []\n",
    "for i in range(0, len(story_boundaries['43'])):\n",
    "    tag = 0\n",
    "    for j in range(2,5):\n",
    "        if i == int(soc_event[j][0,0] - 1):\n",
    "            tag += 1\n",
    "        elif i == int(loc_event[j][0,0] - 1):\n",
    "            tag += 1\n",
    "    if tag == 0:\n",
    "        sum_recall = sum(loc_subj_sent_m[:, i])    \n",
    "        avg_recall = sum_recall/n_location\n",
    "        LP_non_start_cols.append(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Averages of all sentence types\n",
    "#output: SP_avg_all_sents= [social-event-starts, location-event-starts, non-event-starts]\n",
    "\n",
    "LP_avg_all_sents = [statistics.mean(LP_SE), statistics.mean(LP_LE), statistics.mean(LP_non_start_cols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III: Graphing\n",
    "## Step 1: Graph of the averages of the sentence types for each priming group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
