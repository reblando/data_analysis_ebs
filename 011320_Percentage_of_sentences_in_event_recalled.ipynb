{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Sentences Defining Event Boundaries\n",
    "# I: All Participants\n",
    "# II: Social Primed Participants\n",
    "# III: Location Primed Participants\n",
    "# IV: Graphing\n",
    "# V: Printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd\n",
    "import pickle\n",
    "import seaborn as sb\n",
    "\n",
    "%autosave 5\n",
    "\n",
    "#import Alex-scored free recall sheets for story 43\n",
    "xls43 = pd.ExcelFile('/Users/alexreblando/Documents/Baldassano Lab/43_Alex.xlsx')\n",
    "\n",
    "#get sheet names\n",
    "xls = xlrd.open_workbook(r'/Users/alexreblando/Documents/Baldassano Lab/43_Alex.xlsx', on_demand=True)\n",
    "sheet_names = xls.sheet_names()\n",
    "\n",
    "#import story stats in order to get story lengths\n",
    "pickle_in = open(\"story_stats.pickle\",\"rb\")\n",
    "story_stats = pickle.load(pickle_in)\n",
    "\n",
    "#import story boundaries to get putative event boundaries\n",
    "pickle_in = open(\"story_boundaries.pickle\",\"rb\")\n",
    "story_boundaries = pickle.load(pickle_in)\n",
    "\n",
    "#import subj_schemas matrix so that for each story for each subject you can know if they are\n",
    "#social or location primed\n",
    "pickle_in = open(\"subj_schemas.pickle\",\"rb\")\n",
    "subj_schemas = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0: Sentences defining event boundaries\n",
    "## Step 1: Social Events\n",
    "## Step 2: Location Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Determining the story sentences that mark the boundaries of each social event\n",
    "soc_event = {}\n",
    "\n",
    "#make the dictionary of all the events\n",
    "for i in range(1,5):\n",
    "    soc_event[i] = np.zeros((1,3))\n",
    "\n",
    "count = 1\n",
    "for j in range(len(story_boundaries['43'])):\n",
    "    if story_boundaries['43'][j, 1] == 1:\n",
    "        if count == 1:\n",
    "            soc_event[count][0,0] = 1\n",
    "            count = 2\n",
    "        else:\n",
    "            soc_event[count-1][0,1] = j\n",
    "            soc_event[count][0,0] = j+1\n",
    "            count += 1\n",
    "        \n",
    "soc_event[4][0,1] = len(story_boundaries['43']) \n",
    "\n",
    "#length of each event\n",
    "for i in range(1,5):\n",
    "    soc_event[i][0,2] = soc_event[i][0,1] - soc_event[i][0,0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Determining the story sentences that define the location events\n",
    "loc_event = {}\n",
    "\n",
    "#make the dictionary of all the events\n",
    "for i in range(1,5):\n",
    "    loc_event[i] = np.zeros((1,3))\n",
    "\n",
    "count = 1\n",
    "for j in range(len(story_boundaries['43'])):\n",
    "    if story_boundaries['43'][j, 0] == 1:\n",
    "        if count == 1:\n",
    "            loc_event[count][0,0] = 1\n",
    "            count = 2\n",
    "        else:\n",
    "            loc_event[count-1][0,1] = j\n",
    "            loc_event[count][0,0] = j+1\n",
    "            count += 1\n",
    "            \n",
    "        \n",
    "loc_event[4][0,1] = len(story_boundaries['43']) \n",
    "\n",
    "#length of each event\n",
    "for i in range(1,5):\n",
    "    loc_event[i][0,2] = loc_event[i][0,1] - loc_event[i][0,0] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I: All participants (no differentiation based on priming)\n",
    "## Step 1: Dictionary of scored sheets of individual participants\n",
    "## Step 2: Participant x Story Sentence matrix\n",
    "## Step 3: Participant x Event matrix\n",
    "### Part 1: Social Events\n",
    "### Part 2: Location Events\n",
    "## Step 4: Average Participant x Event matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Dictionary of scored sheets of individual participants\n",
    "rs_dict = {}\n",
    "\n",
    "for name in sheet_names:\n",
    "    rs_dict[name] = pd.read_excel(xls43, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Participant x Story sentence matrix with '1' values for sentences that that \n",
    "#participant mentioned in their free recall\n",
    "\n",
    "#find the number of sentences in story 43\n",
    "n_sent = story_stats['43'][3]\n",
    "n_participants = len(sheet_names)\n",
    "subj_sent_m = np.zeros((n_participants, n_sent))\n",
    "count = 0\n",
    "\n",
    "for name in sheet_names:\n",
    "    for i in range(n_sent):\n",
    "        val = np.sum(rs_dict[name][i+1])\n",
    "        if val > 0:\n",
    "            val = 1\n",
    "        subj_sent_m[count, i] = val\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Participant x Event matrix\n",
    "# Part 1: Social Events\n",
    "\n",
    "soc_partic_event = np.zeros((n_participants, 4))\n",
    "\n",
    "for k in range(0, n_participants):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(soc_event[i][0,0])\n",
    "        stop = int(soc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        soc_partic_event[k][i-1] = count/soc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.25      , 0.25      , 0.5       ],\n",
       "       [0.2       , 0.375     , 0.41666667, 0.        ],\n",
       "       [0.4       , 0.5       , 0.25      , 0.        ],\n",
       "       [0.2       , 0.5       , 0.33333333, 0.25      ],\n",
       "       [0.2       , 0.125     , 0.16666667, 0.25      ],\n",
       "       [0.2       , 0.25      , 0.16666667, 0.25      ],\n",
       "       [0.        , 0.375     , 0.41666667, 0.5       ],\n",
       "       [0.6       , 0.875     , 0.16666667, 0.75      ],\n",
       "       [0.2       , 0.625     , 0.41666667, 0.25      ],\n",
       "       [0.4       , 0.125     , 0.08333333, 0.        ],\n",
       "       [0.6       , 0.75      , 0.5       , 0.        ],\n",
       "       [0.2       , 0.625     , 0.25      , 0.25      ],\n",
       "       [0.4       , 0.375     , 0.41666667, 0.25      ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soc_partic_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Location Events\n",
    "\n",
    "loc_partic_event = np.zeros((n_participants, 4))\n",
    "\n",
    "for k in range(0, n_participants):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(loc_event[i][0,0])\n",
    "        stop = int(loc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        loc_partic_event[k][i-1] = count/loc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Average Participant x Event Matrix\n",
    "\n",
    "avg_soc_part_event = np.mean(soc_partic_event, axis = 0)\n",
    "avg_loc_part_event = np.mean(loc_partic_event, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Social Primed Participants\n",
    "## Step 1: Participant x Story Sentence matrix\n",
    "## Step 3: Participant x Event matrix\n",
    "### Part 1: Social Events\n",
    "### Part 2: Location Events\n",
    "## Step 4: Average Participant x Event matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: make a participant x story sentence matrix with '1' values for sentences that that \n",
    "#participant mentioned in their free recall for social primed participants\n",
    "\n",
    "#find the number of sentences in story 43\n",
    "n_sent = story_stats['43'][3]\n",
    "\n",
    "#the number of social primed participants\n",
    "n_social = (sum( x == 'Social' for x in subj_schemas['43'].values()))\n",
    "\n",
    "#make empty participant x story sentences matrix\n",
    "soc_subj_sent_m = np.zeros((n_social, n_sent))\n",
    "count = 0\n",
    "for name in sheet_names:\n",
    "    if subj_schemas['43'][name] == 'Social':\n",
    "        for i in range(n_sent):\n",
    "            val = np.sum(rs_dict[name][i+1])\n",
    "            if val > 0:\n",
    "                val = 1\n",
    "            soc_subj_sent_m[count, i] = val\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Participant x Event matrix\n",
    "# Part 1: Social Events\n",
    "\n",
    "SP_soc_partic_event = np.zeros((n_social, 4))\n",
    "\n",
    "for k in range(0, n_social):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(soc_event[i][0,0])\n",
    "        stop = int(soc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        SP_soc_partic_event[k][i-1] = count/soc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Location Events\n",
    "\n",
    "SP_loc_partic_event = np.zeros((n_social, 4))\n",
    "\n",
    "for k in range(0, n_social):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(loc_event[i][0,0])\n",
    "        stop = int(loc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        SP_loc_partic_event[k][i-1] = count/loc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Average Participant x Event matrix\n",
    "\n",
    "avg_SP_soc_part_event = np.mean(SP_soc_partic_event, axis = 0)\n",
    "avg_SP_loc_part_event = np.mean(SP_loc_partic_event, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Location Primed Participants\n",
    "## Step 1: Participant x Story Sentence matrix\n",
    "## Step 3: Participant x Event matrix\n",
    "### Part 1: Social Events\n",
    "### Part 2: Location Events\n",
    "## Step 4: Average Participant x Event matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 1: make a participant x story sentence matrix with '1' values for sentences that that \n",
    "#participant mentioned in their free recall for social primed participants\n",
    "\n",
    "#find the number of sentences in story 43\n",
    "n_sent = story_stats['43'][3]\n",
    "\n",
    "#the number of social primed participants\n",
    "n_location = (sum( x == 'Location' for x in subj_schemas['43'].values()))\n",
    "\n",
    "#make empty participant x story sentences matrix\n",
    "loc_subj_sent_m = np.zeros((n_location, n_sent))\n",
    "count = 0\n",
    "for name in sheet_names:\n",
    "    if subj_schemas['43'][name] == 'Location':\n",
    "        for i in range(n_sent):\n",
    "            val = np.sum(rs_dict[name][i+1])\n",
    "            if val > 0:\n",
    "                val = 1\n",
    "            loc_subj_sent_m[count, i] = val\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Participant x Event matrix\n",
    "# Part 1: Social Events\n",
    "\n",
    "LP_soc_partic_event = np.zeros((n_location, 4))\n",
    "\n",
    "for k in range(0, n_location):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(soc_event[i][0,0])\n",
    "        stop = int(soc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        LP_soc_partic_event[k][i-1] = count/soc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Location Events\n",
    "\n",
    "LP_loc_partic_event = np.zeros((n_location, 4))\n",
    "\n",
    "for k in range(0, n_location):\n",
    "    #events\n",
    "    for i in range(1,5):\n",
    "        start = int(loc_event[i][0,0])\n",
    "        stop = int(loc_event[i][0,1])\n",
    "        count = 0\n",
    "        for j in range(start, stop):\n",
    "            if subj_sent_m[k][j] == 1:\n",
    "                count += 1\n",
    "        LP_loc_partic_event[k][i-1] = count/loc_event[i][0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Average Participant x Event matrix\n",
    "\n",
    "avg_LP_soc_part_event = np.mean(LP_soc_partic_event, axis = 0)\n",
    "avg_LP_loc_part_event = np.mean(LP_loc_partic_event, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1        0.425      0.18571429 0.39090909]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2754058441558441"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_LP_loc_part_event)\n",
    "np.mean(avg_LP_loc_part_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28       0.4        0.26666667 0.275     ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30541666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_LP_soc_part_event)\n",
    "np.mean(avg_LP_soc_part_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08333333 0.5        0.25       0.36363636]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.29924242424242425"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_SP_loc_part_event)\n",
    "np.mean(avg_SP_loc_part_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3     0.40625 0.3125  0.1875 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3015625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(avg_SP_soc_part_event)\n",
    "np.mean(avg_SP_soc_part_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.25      , 0.25      , 0.5       ],\n",
       "       [0.2       , 0.375     , 0.41666667, 0.        ],\n",
       "       [0.4       , 0.5       , 0.25      , 0.        ],\n",
       "       [0.2       , 0.5       , 0.33333333, 0.25      ],\n",
       "       [0.2       , 0.125     , 0.16666667, 0.25      ],\n",
       "       [0.2       , 0.25      , 0.16666667, 0.25      ],\n",
       "       [0.        , 0.375     , 0.41666667, 0.5       ],\n",
       "       [0.6       , 0.875     , 0.16666667, 0.75      ],\n",
       "       [0.2       , 0.625     , 0.41666667, 0.25      ],\n",
       "       [0.4       , 0.125     , 0.08333333, 0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LP_soc_partic_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
