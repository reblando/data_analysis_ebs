{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "\n",
    "plotly.tools.set_credentials_file(username='amr7', api_key='4gj9vxlD7C63cCRCaRdU')\n",
    "\n",
    "#iMac\n",
    "#directory = '/Users/alexreblando/Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/ebs/usable_data'\n",
    "\n",
    "#laptop\n",
    "directory = '/Users/alexreblando/Documents/GitHub/ebs/usable_data'\n",
    "directory_stories = '/Users/alexreblando/Documents/GitHub/ebs/story_xlsx_files'\n",
    "\n",
    "filenames = glob.glob(directory+ '/*.csv')\n",
    "filenames_stories = glob.glob(directory_stories + '/*.xlsx')\n",
    "\n",
    "dfs = []\n",
    "dfs_stories = []\n",
    "\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "    \n",
    "for filename in filenames_stories:\n",
    "    dfs_stories.append(pd.read_excel(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'story': '33', 'schema': 'Location'}, 2: {'story': '13', 'schema': 'Social'}, 3: {'story': '24', 'schema': 'Social'}, 4: {'story': '21', 'schema': 'Location'}, 5: {'story': '44', 'schema': 'Location'}, 6: {'story': '12', 'schema': 'Location'}, 7: {'story': '32', 'schema': 'Social'}, 8: {'story': '41', 'schema': 'Social'}}\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary for each participant, documenting which stories they read paired with the schema \n",
    "#they were assigned for that story\n",
    "size_dfs = len(dfs)\n",
    "participants = dict()\n",
    "\n",
    "for s in range(size_dfs):\n",
    "    this_dict = dict()\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    this_p = dfs[s]['participant'].iloc[0]\n",
    "    for i in range(8):\n",
    "        final_dict = {\n",
    "            'story':story_list[i],\n",
    "            'schema':schema_list[i],\n",
    "        }\n",
    "        \n",
    "        this_dict[i+1] = final_dict\n",
    "        \n",
    "    participants[this_p] = this_dict\n",
    "\n",
    "print(participants['030419_p2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is super fancy, with high ceilings, chandeliers, and a fire place.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = dfs[0].loc[dfs[0]['count'] == 3]\n",
    "this = 'question'+str(1)+'_answer'\n",
    "x = pd.notna(z[this])\n",
    "\n",
    "for i in range(len(z)):\n",
    "    if x.iloc[i] == True:\n",
    "        hold = z['question1_answer'].iloc[i]\n",
    "    \n",
    "hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' 'hello' '1' '2' '3' '4']\n",
      "['1' '2' '3' '4']\n",
      "['3' '4' '1' '2']\n",
      "['4' 'hello' '3' '4' '1' '2']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-9a9db09fe67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mvalues2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mvalues2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#indexing into a matrix\n",
    "z = '4'\n",
    "b = 'hello'\n",
    "\n",
    "h = np.array([z, b, '1', '2', '3', '4'])\n",
    "print(h)\n",
    "temp = h[2:6]\n",
    "print(temp)\n",
    "temp =  np.roll(temp, 2)\n",
    "print(temp)\n",
    "h[2:6] = temp\n",
    "print(h)\n",
    "r = 'l'\n",
    "g = 'o'\n",
    "q = '5'\n",
    "values2 = [r,g]\n",
    "values2.append(q)\n",
    "h = np.vstack([h, values2])\n",
    "print(h)\n",
    "\n",
    "v = h[h[:,0] == '4']\n",
    "v[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary for the answers to the 8 questions for each story, not parsing the questions \n",
    "#by primed or unprimed\n",
    "\n",
    "question_answers = dict()\n",
    "\n",
    "for s in range(size_dfs):\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    #if the data file has a question portion\n",
    "    if 'question1_answer' in dfs[s].columns:\n",
    "        \n",
    "        #get the question order of the stories (\"primed v not-primed first\")\n",
    "        question_order = dfs[s]['order of question']\n",
    "        which_one = pd.notna(question_order)\n",
    "        question_order_list = []\n",
    "        for k in range(len(question_order)):\n",
    "            if which_one[k] == True:\n",
    "                question_order_list.append(question_order[k])  \n",
    "        \n",
    "        #loop through all the stories \n",
    "        for i in range(8):\n",
    "            new_questions = [dfs[s]['participant'].iloc[0], story_list[i], schema_list[i]]\n",
    "            which_rows = dfs[s].loc[dfs[s]['count'] == i]\n",
    "            tally_completed = 0\n",
    "            #loop through all the questions\n",
    "            for j in range(8):\n",
    "                this_question = 'question'+str(j+1)+'_answer'\n",
    "                which_cell = pd.notna(which_rows[this_question])\n",
    "                any_answer = np.any(which_cell)\n",
    "                if any_answer == False:\n",
    "                    new_questions.append('')\n",
    "                else:\n",
    "                    for t in range(len(which_rows)):\n",
    "                        if which_cell.iloc[t] == True:\n",
    "                            hold = which_rows[this_question].iloc[t]\n",
    "                            tally_completed = tally_completed + 1\n",
    "                    new_questions.append(hold)\n",
    "            \n",
    "            #move the order of the stories, so that location questions always come first\n",
    "            if tally_completed > 0:\n",
    "                if question_order_list[i] == 'primed first' and schema_list[i] == 'Social':\n",
    "                    temp = new_questions[3:12]\n",
    "                    temp = np.roll(temp, 4)\n",
    "                    new_questions[3:12] = temp\n",
    "                if question_order_list[i] == 'non-primed first' and schema_list[i] == 'Location':\n",
    "                    temp = new_questions[3:12]\n",
    "                    temp = np.roll(temp, 4)\n",
    "                    new_questions[3:12] = temp\n",
    "                    \n",
    "            #put all of the questions into dictionaries organized by story\n",
    "            if story_list[i] in question_answers:\n",
    "                question_answers[story_list[i]] = np.vstack((question_answers[story_list[i]], new_questions))\n",
    "            else:\n",
    "                question_answers[story_list[i]] = new_questions\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export each story answers to its own csv file\n",
    "import csv\n",
    "\n",
    "for key in question_answers:\n",
    "    title = key + '_recall_answers.csv'\n",
    "    this_array = question_answers[key]\n",
    "    with open(title, 'w') as csvfile:\n",
    "        fieldnames = ['participant', 'story', 'schema', '1', '2', '3', '4','5', '6','7','8']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(this_array)):\n",
    "            a = this_array[i, 0]\n",
    "            b = this_array[i, 1]\n",
    "            c = this_array[i, 2]\n",
    "            d = this_array[i, 3]\n",
    "            e = this_array[i, 4]\n",
    "            f = this_array[i, 5]\n",
    "            g = this_array[i, 6]\n",
    "            h = this_array[i, 7]\n",
    "            j = this_array[i, 8]\n",
    "            k = this_array[i, 9]\n",
    "            l = this_array[i, 10]\n",
    "            writer.writerow({'participant': a, 'story': b, 'schema': c, '1': d, '2': e, '3': f, '4':g, '5':h, '6':j, '7':k,'8':l})\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030119_p2\n",
      "Social\n",
      "8\n",
      "030119_p3\n",
      "Location\n",
      "7\n",
      "030419_p2\n",
      "Location\n",
      "5\n",
      "030519_p1\n",
      "Location\n",
      "6\n",
      "030719_p2\n",
      "Location\n",
      "1\n",
      "030819_p1\n",
      "Social\n",
      "4\n",
      "031219_p1\n",
      "Social\n",
      "2\n",
      "031319_p1\n",
      "Social\n",
      "5\n",
      "031319_p2\n",
      "Location\n",
      "2\n",
      "031519_p2\n",
      "Social\n",
      "4\n",
      "031519_p3\n",
      "Social\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#return participants who have read a particular story\n",
    "this_one = '44'\n",
    "\n",
    "for key in participants:\n",
    "    for key2 in participants[key]:\n",
    "        if participants[key][key2]['story'] == this_one:\n",
    "            print(key)\n",
    "            print(participants[key][key2]['schema'])\n",
    "            print(key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the key presses into a dictionary, orginized by story\n",
    "size_dfs = len(dfs)\n",
    "loc_story_keys = dict()\n",
    "soc_story_keys = dict()\n",
    "for s in range(size_dfs):\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    for i in range(8):\n",
    "        keys = dfs[s]['story_presses.keys'].values[dfs[s]['count']==i]\n",
    "        keys = keys[~np.isnan(keys)]\n",
    "        if schema_list[i] == 'Location':\n",
    "            if story_list[i] in loc_story_keys:\n",
    "                loc_story_keys[story_list[i]] = np.concatenate((loc_story_keys[story_list[i]],keys[:,np.newaxis]), axis=1)\n",
    "            else:\n",
    "                loc_story_keys[story_list[i]] = keys[:, np.newaxis]\n",
    "        elif schema_list[i] == 'Social':\n",
    "            if story_list[i] in soc_story_keys:\n",
    "                soc_story_keys[story_list[i]] = np.concatenate((soc_story_keys[story_list[i]],keys[:,np.newaxis]), axis=1)\n",
    "            else:\n",
    "                soc_story_keys[story_list[i]] = keys[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the stories into a dictionary\n",
    "\n",
    "all_story_priors = dict()\n",
    "\n",
    "for s in range(16):\n",
    "    this_story = str(int(dfs_stories[s]['story'].iloc[0]))\n",
    "    keys2 = dfs_stories[s]['locationEvent'].values\n",
    "    keys3 = dfs_stories[s]['socialEvent'].values\n",
    "    all_story_priors[this_story] = keys2[:, np.newaxis]\n",
    "    all_story_priors[this_story] = np.concatenate((all_story_priors[this_story], keys3[:, np.newaxis]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for participant responses, convert all '1' presses to 0 values, and '9' presses to 1 values\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    this_array = soc_story_keys[key]\n",
    "    this_array[this_array ==1] = 0\n",
    "    this_array[this_array == 9] = 1\n",
    "    soc_story_keys[key] = this_array\n",
    "    \n",
    "for key in loc_story_keys:\n",
    "    this_array = loc_story_keys[key]\n",
    "    this_array[this_array ==1] = 0\n",
    "    this_array[this_array == 9] = 1\n",
    "    loc_story_keys[key] = this_array\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum the responses\n",
    "loc_percent_story_keys = dict()\n",
    "soc_percent_story_keys = dict()\n",
    "\n",
    "for key in loc_story_keys:\n",
    "    this_sum = np.sum(loc_story_keys[key], axis = 1)\n",
    "    N = np.size(loc_story_keys[key],1)\n",
    "    this_percent = this_sum/N\n",
    "    loc_percent_story_keys[key] = this_percent[:, np.newaxis]\n",
    "    \n",
    "for key in soc_story_keys:\n",
    "    this_sum = np.sum(soc_story_keys[key], axis = 1)\n",
    "    N = np.size(soc_story_keys[key],1)\n",
    "    this_percent = this_sum/N\n",
    "    soc_percent_story_keys[key] = this_percent[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.375 7.836021044283356 5.75 2.2718473369882592\n"
     ]
    }
   ],
   "source": [
    "#find the average number and standard deviation of participants in each story \n",
    "#also for story lengths\n",
    "\n",
    "lengths = []\n",
    "N = []\n",
    "\n",
    "for key in loc_story_keys:\n",
    "    x, y = loc_story_keys[key].shape\n",
    "    x1, y1 = soc_story_keys[key].shape\n",
    "    lengths.append(x)\n",
    "    lengths.append(x1)\n",
    "    N.append(y)\n",
    "    N.append(y1)\n",
    "    \n",
    "length_mean = statistics.mean(lengths)\n",
    "length_sd = statistics.stdev(lengths)\n",
    "\n",
    "N_mean = statistics.mean(N)\n",
    "N_sd = statistics.stdev(N)\n",
    "print(length_mean, length_sd, N_mean, N_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in all_story_priors:\n",
    "    location = all_story_priors[key][:,0]\n",
    "    social = all_story_priors[key][:,1]\n",
    "    for i in range(0, len(location)):  \n",
    "        if location[i] > location[i-1]:\n",
    "            location[i] = 7\n",
    "    for i in range(0, len(location)):  \n",
    "        if location[i] != 7:\n",
    "            location[i] = 0\n",
    "    for i in range(0, len(social)):\n",
    "        if social[i] > social[i - 1]:\n",
    "            social[i] = 7\n",
    "    for i in range(0, len(social)):\n",
    "        if social[i] != 7:\n",
    "            social[i] = 0\n",
    "    location[0] = 7\n",
    "    social[0] = 7\n",
    "    location2 = location > 1\n",
    "    social2 = social > 1\n",
    "    location2 = location2.astype(int)\n",
    "    social2 = social2.astype(int)\n",
    "    all_story_priors[key] = np.concatenate((all_story_priors[key], location2[:, np.newaxis]), axis = 1) \n",
    "    all_story_priors[key] = np.concatenate((all_story_priors[key], social2[:, np.newaxis]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexreblando/anaconda3/lib/python3.7/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~amr7/146.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the stories\n",
    "key = '13'\n",
    "opacityPriors = 0.1\n",
    "\n",
    "new_x = np.arange(len(all_story_priors[key]) + 1)\n",
    "#new_x = np.delete(x_index, 0)\n",
    "trace1 = go.Scatter(x = new_x, \n",
    "                y = all_story_priors[key][:,2], \n",
    "                mode = 'lines+markers', \n",
    "                name = 'location Event Starts',\n",
    "                line = dict(\n",
    "                    shape = 'hvh',\n",
    "                    color = ('rgba(0, 204, 0, .05)'),\n",
    "                    width = 4))\n",
    "\n",
    "trace2 = go.Scatter(x = new_x, \n",
    "                y = all_story_priors[key][:,3], \n",
    "                mode = 'lines+markers', \n",
    "                name = 'social Event Starts',\n",
    "                line = dict(\n",
    "                    shape = 'hvh',\n",
    "                    color = ('rgba(255, 91, 71, .05)'),\n",
    "                    width = 4))\n",
    "\n",
    "trace3 = go.Scatter(x = new_x, \n",
    "                    y = loc_percent_story_keys[key], \n",
    "                    mode = 'lines+markers', \n",
    "                    name = 'participant w location',\n",
    "                    line = dict(\n",
    "                        shape = 'hvh',\n",
    "                        color = ('rgba(0, 191, 255, .5)'),\n",
    "                        width = 4))\n",
    "\n",
    "trace4 = go.Scatter(x = new_x, \n",
    "                    y = soc_percent_story_keys[key], \n",
    "                    mode = 'lines+markers', \n",
    "                    name = 'participants w social',\n",
    "                    line = dict(\n",
    "                        shape = 'hvh',\n",
    "                        color = ('rgba(255, 215, 0, .5)'),\n",
    "                        width = 4))\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    title= key,\n",
    "    xaxis=dict(\n",
    "        title='Sentence Number',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f')\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks='',\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(soc_story_keys['33'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12': 0.1577916642824127, '31': 0.3302002762169798, '43': 0.3545245679456396, '24': 0.2336487172178229, '23': 0.20985257489672077, '11': 0.21468811705803534, '32': 0.1433510385893565, '44': 0.16894675451510968, '21': 0.24042685608175898, '33': 0.11916350888251724, '42': 0.19523681250099525, '14': 0.46291855274635, '13': 0.18156825980064079, '41': 0.1932993111817978, '34': 0.21484985796747316, '22': 0.09966453255402896}\n",
      "12\n",
      "loc: 0.19955380489428873\n",
      "soc: 0.1577916642824127\n",
      "31\n",
      "loc: 0.3445297430531166\n",
      "soc: 0.3302002762169798\n",
      "43\n",
      "loc: 0.16839215754740292\n",
      "soc: 0.3545245679456396\n",
      "24\n",
      "loc: 0.14463698498546107\n",
      "soc: 0.2336487172178229\n",
      "23\n",
      "loc: 0.306308013876848\n",
      "soc: 0.20985257489672077\n",
      "11\n",
      "loc: 0.37711864406779627\n",
      "soc: 0.21468811705803534\n",
      "32\n",
      "loc: 0.27504899982976055\n",
      "soc: 0.1433510385893565\n",
      "44\n",
      "loc: 0.5805339172842425\n",
      "soc: 0.16894675451510968\n",
      "21\n",
      "loc: 0.3825291232432217\n",
      "soc: 0.24042685608175898\n",
      "33\n",
      "loc: 0.10887759855396663\n",
      "soc: 0.11916350888251724\n",
      "42\n",
      "loc: 0.16630071268405713\n",
      "soc: 0.19523681250099525\n",
      "14\n",
      "loc: 0.4747213305872215\n",
      "soc: 0.46291855274635\n",
      "13\n",
      "loc: 0.2552259519638095\n",
      "soc: 0.18156825980064079\n",
      "41\n",
      "loc: 0.25948586451929634\n",
      "soc: 0.1932993111817978\n",
      "34\n",
      "loc: 0.2405991214759391\n",
      "soc: 0.21484985796747316\n",
      "22\n",
      "loc: 0.2721265884378497\n",
      "soc: 0.09966453255402896\n"
     ]
    }
   ],
   "source": [
    "#find the mean correlation of the responses of participants with the same schema for each story and store the\n",
    "#value in a dictionary\n",
    "soc_cor = dict()\n",
    "loc_cor = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    z = len(soc_story_keys[key][0])\n",
    "    soc_this = np.nanmean(np.corrcoef(soc_story_keys[key].T)[np.triu(np.ones((z,z), dtype=np.bool),1)])\n",
    "    soc_cor[key] = soc_this\n",
    "    g = len(loc_story_keys[key][0])\n",
    "    loc_this = np.nanmean(np.corrcoef(loc_story_keys[key].T)[np.triu(np.ones((g,g), dtype=np.bool),1)])\n",
    "    loc_cor[key] = loc_this\n",
    "    \n",
    "print(soc_cor)\n",
    "\n",
    "for key in soc_cor:\n",
    "    print(key)\n",
    "    print('loc:', loc_cor[key])\n",
    "    print('soc:', soc_cor[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36012283858321603\n"
     ]
    }
   ],
   "source": [
    "#find the averages of correlations across location schemas\n",
    "\n",
    "loc_this_sum = loc_cor['14'] + loc_cor['24'] + loc_cor['34'] + loc_cor['44']\n",
    "mean_loc = loc_this_sum/4\n",
    "print(mean_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2058440760392831\n"
     ]
    }
   ],
   "source": [
    "#find the averages of correlations across social schemas\n",
    "\n",
    "soc_this_sum = soc_cor['41'] + soc_cor['42'] + soc_cor['43'] + soc_cor['44']\n",
    "mean_soc = soc_this_sum/4\n",
    "print(mean_soc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12': 0.25664832661326425, '31': 0.38817565595027176, '43': 0.20043573877826265, '24': 0.15119165888307928, '23': 0.19438594801316078, '11': 0.24783198743442642, '32': 0.11318534025583046, '44': 0.17222516231954957, '21': 0.34683027578511294, '33': 0.18540924799423916, '42': 0.15655942054250466, '14': 0.4198602962574182, '13': 0.23352754960792155, '41': 0.20204691261880536, '34': 0.17746907126500122, '22': 0.16184556064948866}\n"
     ]
    }
   ],
   "source": [
    "#correlation across the schemas \n",
    "isc_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    z = len(soc_story_keys[key][0])\n",
    "    x = len(loc_story_keys[key][0])\n",
    "    new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "    coef_matrix = np.corrcoef(new.T)\n",
    "    this = coef_matrix[0:z,z:(z+x)]\n",
    "    mean_isc = np.nanmean(this)\n",
    "    isc_dict[key] = mean_isc\n",
    "    \n",
    "print(isc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the participants' answers to questions into dictionaries categorized by story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' 'hello']\n",
      "[['4' 'hello']\n",
      " ['l' 'o']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
