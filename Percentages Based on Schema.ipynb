{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plotly.tools.set_credentials_file(username='amr7', api_key='4gj9vxlD7C63cCRCaRdU')\n",
    "\n",
    "#iMac\n",
    "#directory = '/Users/alexreblando/Library/Mobile Documents/com~apple~CloudDocs/Documents/GitHub/ebs/usable_data'\n",
    "\n",
    "#laptop\n",
    "directory = '/Users/alexreblando/Documents/GitHub/ebs/usable_data'\n",
    "directory_stories = '/Users/alexreblando/Documents/GitHub/ebs/story_xlsx_files'\n",
    "\n",
    "filenames = glob.glob(directory+ '/*.csv')\n",
    "filenames_stories = glob.glob(directory_stories + '/*.xlsx')\n",
    "\n",
    "dfs = []\n",
    "dfs_stories = []\n",
    "\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "    \n",
    "for filename in filenames_stories:\n",
    "    dfs_stories.append(pd.read_excel(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary for each participant, documenting which stories they read paired with the schema \n",
    "#they were assigned for that story\n",
    "size_dfs = len(dfs)\n",
    "participants = dict()\n",
    "\n",
    "for s in range(size_dfs):\n",
    "    this_dict = dict()\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    this_p = dfs[s]['participant'].iloc[0]\n",
    "    for i in range(8):\n",
    "        final_dict = {\n",
    "            'story':story_list[i],\n",
    "            'schema':schema_list[i],\n",
    "        }\n",
    "        \n",
    "        this_dict[i+1] = final_dict\n",
    "        \n",
    "    participants[this_p] = this_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = dfs[0].loc[dfs[0]['count'] == 3]\n",
    "this = 'question'+str(1)+'_answer'\n",
    "x = pd.notna(z[this])\n",
    "\n",
    "for i in range(len(z)):\n",
    "    if x.iloc[i] == True:\n",
    "        hold = z['question1_answer'].iloc[i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' 'hello' '1' '2' '3' '4']\n",
      "['1' '2' '3' '4']\n",
      "['3' '4' '1' '2']\n",
      "['4' 'hello' '3' '4' '1' '2']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9a9db09fe67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mvalues2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mvalues2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#indexing into a matrix\n",
    "z = '4'\n",
    "b = 'hello'\n",
    "\n",
    "h = np.array([z, b, '1', '2', '3', '4'])\n",
    "print(h)\n",
    "temp = h[2:6]\n",
    "print(temp)\n",
    "temp =  np.roll(temp, 2)\n",
    "print(temp)\n",
    "h[2:6] = temp\n",
    "print(h)\n",
    "r = 'l'\n",
    "g = 'o'\n",
    "q = '5'\n",
    "values2 = [r,g]\n",
    "values2.append(q)\n",
    "h = np.vstack([h, values2])\n",
    "print(h)\n",
    "\n",
    "v = h[h[:,0] == '4']\n",
    "v[0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary for the answers to the 8 questions for each story, not parsing the questions \n",
    "#by primed or unprimed\n",
    "\n",
    "question_answers = dict()\n",
    "\n",
    "for s in range(size_dfs):\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    #if the data file has a question portion\n",
    "    if 'question1_answer' in dfs[s].columns:\n",
    "        \n",
    "        #get the question order of the stories (\"primed v not-primed first\")\n",
    "        question_order = dfs[s]['order of question']\n",
    "        which_one = pd.notna(question_order)\n",
    "        question_order_list = []\n",
    "        for k in range(len(question_order)):\n",
    "            if which_one[k] == True:\n",
    "                question_order_list.append(question_order[k])  \n",
    "        \n",
    "        #loop through all the stories \n",
    "        for i in range(8):\n",
    "            new_questions = [dfs[s]['participant'].iloc[0], story_list[i], schema_list[i]]\n",
    "            which_rows = dfs[s].loc[dfs[s]['count'] == i]\n",
    "            tally_completed = 0\n",
    "            #loop through all the questions\n",
    "            for j in range(8):\n",
    "                this_question = 'question'+str(j+1)+'_answer'\n",
    "                which_cell = pd.notna(which_rows[this_question])\n",
    "                any_answer = np.any(which_cell)\n",
    "                if any_answer == False:\n",
    "                    new_questions.append('')\n",
    "                else:\n",
    "                    for t in range(len(which_rows)):\n",
    "                        if which_cell.iloc[t] == True:\n",
    "                            hold = which_rows[this_question].iloc[t]\n",
    "                            tally_completed = tally_completed + 1\n",
    "                    new_questions.append(hold)\n",
    "            \n",
    "            #move the order of the stories, so that location questions always come first\n",
    "            if tally_completed > 0:\n",
    "                if question_order_list[i] == 'primed first' and schema_list[i] == 'Social':\n",
    "                    temp = new_questions[3:12]\n",
    "                    temp = np.roll(temp, 4)\n",
    "                    new_questions[3:12] = temp\n",
    "                if question_order_list[i] == 'non-primed first' and schema_list[i] == 'Location':\n",
    "                    temp = new_questions[3:12]\n",
    "                    temp = np.roll(temp, 4)\n",
    "                    new_questions[3:12] = temp\n",
    "                    \n",
    "            #put all of the questions into dictionaries organized by story\n",
    "            if story_list[i] in question_answers:\n",
    "                question_answers[story_list[i]] = np.vstack((question_answers[story_list[i]], new_questions))\n",
    "            else:\n",
    "                question_answers[story_list[i]] = new_questions\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question_answers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-34c9059db1dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion_answers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'raw_recall/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_recall_answers.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mthis_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion_answers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'question_answers' is not defined"
     ]
    }
   ],
   "source": [
    "#export each story answers to its own csv file\n",
    "import csv\n",
    "\n",
    "for key in question_answers:\n",
    "    title = 'raw_recall/'+ key + '_recall_answers.csv'\n",
    "    this_array = question_answers[key]\n",
    "    with open(title, 'w') as csvfile:\n",
    "        fieldnames = ['participant', 'story', 'schema', '1', '2', '3', '4','5', '6','7','8']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for i in range(len(this_array)):\n",
    "            a = this_array[i, 0]\n",
    "            b = this_array[i, 1]\n",
    "            c = this_array[i, 2]\n",
    "            d = this_array[i, 3]\n",
    "            e = this_array[i, 4]\n",
    "            f = this_array[i, 5]\n",
    "            g = this_array[i, 6]\n",
    "            h = this_array[i, 7]\n",
    "            j = this_array[i, 8]\n",
    "            k = this_array[i, 9]\n",
    "            l = this_array[i, 10]\n",
    "            writer.writerow({'participant': a, 'story': b, 'schema': c, '1': d, '2': e, '3': f, '4':g, '5':h, '6':j, '7':k,'8':l})\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030119_p2\n",
      "Social\n",
      "8\n",
      "030119_p3\n",
      "Location\n",
      "7\n",
      "030419_p2\n",
      "Location\n",
      "5\n",
      "030519_p1\n",
      "Location\n",
      "6\n",
      "030719_p2\n",
      "Location\n",
      "1\n",
      "030819_p1\n",
      "Social\n",
      "4\n",
      "031219_p1\n",
      "Social\n",
      "2\n",
      "031319_p1\n",
      "Social\n",
      "5\n",
      "031319_p2\n",
      "Location\n",
      "2\n",
      "031519_p2\n",
      "Social\n",
      "4\n",
      "031519_p3\n",
      "Social\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#return participants who have read a particular story\n",
    "this_one = '44'\n",
    "\n",
    "for key in participants:\n",
    "    for key2 in participants[key]:\n",
    "        if participants[key][key2]['story'] == this_one:\n",
    "            print(key)\n",
    "            print(participants[key][key2]['schema'])\n",
    "            print(key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#put all of the key presses into a dictionary, orginized by story\n",
    "size_dfs = len(dfs)\n",
    "loc_story_keys = dict()\n",
    "soc_story_keys = dict()\n",
    "for s in range(size_dfs):\n",
    "    story_list = dfs[s]['order of stories'].iloc[0].split(' ')\n",
    "    story_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in story_list]\n",
    "    schema_list = dfs[s]['order of perspectives'].iloc[0].split(' ')\n",
    "    schema_list = [elem.replace(\"[\",\"\").replace(\"]\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"\\n\",\"\") for elem in schema_list]\n",
    "    schema_list = [elem.replace(\"'\",\"\") for elem in schema_list]\n",
    "    for i in range(8):\n",
    "        keys = dfs[s]['story_presses.keys'].values[dfs[s]['count']==i]\n",
    "        keys = keys[~np.isnan(keys)]\n",
    "        if schema_list[i] == 'Location':\n",
    "            if story_list[i] in loc_story_keys:\n",
    "                loc_story_keys[story_list[i]] = np.concatenate((loc_story_keys[story_list[i]],keys[:,np.newaxis]), axis=1)\n",
    "            else:\n",
    "                loc_story_keys[story_list[i]] = keys[:, np.newaxis]\n",
    "        elif schema_list[i] == 'Social':\n",
    "            if story_list[i] in soc_story_keys:\n",
    "                soc_story_keys[story_list[i]] = np.concatenate((soc_story_keys[story_list[i]],keys[:,np.newaxis]), axis=1)\n",
    "            else:\n",
    "                soc_story_keys[story_list[i]] = keys[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#put all of the a priori story boundaries into a dictionary organized by story\n",
    "\n",
    "all_story_priors = dict()\n",
    "\n",
    "for s in range(16):\n",
    "    this_story = str(int(dfs_stories[s]['story'].iloc[0]))\n",
    "    keys2 = dfs_stories[s]['locationEvent'].values\n",
    "    keys3 = dfs_stories[s]['socialEvent'].values\n",
    "    all_story_priors[this_story] = keys2[:, np.newaxis]\n",
    "    all_story_priors[this_story] = np.concatenate((all_story_priors[this_story], keys3[:, np.newaxis]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for participant responses, convert all '1' presses to 0 values, and '9' presses to 1 values\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    this_array = soc_story_keys[key]\n",
    "    this_array[this_array ==1] = 0\n",
    "    this_array[this_array == 9] = 1\n",
    "    soc_story_keys[key] = this_array\n",
    "    \n",
    "for key in loc_story_keys:\n",
    "    this_array = loc_story_keys[key]\n",
    "    this_array[this_array ==1] = 0\n",
    "    this_array[this_array == 9] = 1\n",
    "    loc_story_keys[key] = this_array\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum the responses\n",
    "loc_percent_story_keys = dict()\n",
    "soc_percent_story_keys = dict()\n",
    "\n",
    "for key in loc_story_keys:\n",
    "    this_sum = np.sum(loc_story_keys[key], axis = 1)\n",
    "    N = np.size(loc_story_keys[key],1)\n",
    "    this_percent = this_sum/N\n",
    "    loc_percent_story_keys[key] = this_percent[:, np.newaxis]\n",
    "    \n",
    "for key in soc_story_keys:\n",
    "    this_sum = np.sum(soc_story_keys[key], axis = 1)\n",
    "    N = np.size(soc_story_keys[key],1)\n",
    "    this_percent = this_sum/N\n",
    "    soc_percent_story_keys[key] = this_percent[:, np.newaxis]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.375 7.836021044283356 5.75 2.2718473369882592\n"
     ]
    }
   ],
   "source": [
    "#find the average number and standard deviation of participants in each story \n",
    "#also for story lengths\n",
    "\n",
    "lengths = []\n",
    "N = []\n",
    "\n",
    "for key in loc_story_keys:\n",
    "    x, y = loc_story_keys[key].shape\n",
    "    x1, y1 = soc_story_keys[key].shape\n",
    "    lengths.append(x)\n",
    "    lengths.append(x1)\n",
    "    N.append(y)\n",
    "    N.append(y1)\n",
    "    \n",
    "length_mean = statistics.mean(lengths)\n",
    "length_sd = statistics.stdev(lengths)\n",
    "\n",
    "N_mean = statistics.mean(N)\n",
    "N_sd = statistics.stdev(N)\n",
    "print(length_mean, length_sd, N_mean, N_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get the binary version of the a priori boundaries\n",
    "\n",
    "for key in all_story_priors:\n",
    "    location = all_story_priors[key][:,0]\n",
    "    social = all_story_priors[key][:,1]\n",
    "    for i in range(0, len(location)):  \n",
    "        if location[i] > location[i-1]:\n",
    "            location[i] = 7\n",
    "    for i in range(0, len(location)):  \n",
    "        if location[i] != 7:\n",
    "            location[i] = 0\n",
    "    for i in range(0, len(social)):\n",
    "        if social[i] > social[i - 1]:\n",
    "            social[i] = 7\n",
    "    for i in range(0, len(social)):\n",
    "        if social[i] != 7:\n",
    "            social[i] = 0\n",
    "    location[0] = 7\n",
    "    social[0] = 7\n",
    "    location2 = location > 1\n",
    "    social2 = social > 1\n",
    "    location2 = location2.astype(int)\n",
    "    social2 = social2.astype(int)\n",
    "    all_story_priors[key] = np.concatenate((all_story_priors[key], location2[:, np.newaxis]), axis = 1) \n",
    "    all_story_priors[key] = np.concatenate((all_story_priors[key], social2[:, np.newaxis]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexreblando/anaconda3/lib/python3.7/site-packages/IPython/core/display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~amr7/152.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the stories\n",
    "key = '13'\n",
    "opacityPriors = 0.1\n",
    "\n",
    "new_x = np.arange(len(all_story_priors[key]) + 1)\n",
    "#new_x = np.delete(x_index, 0)\n",
    "trace1 = go.Scatter(x = new_x, \n",
    "                y = all_story_priors[key][:,2], \n",
    "                mode = 'lines+markers', \n",
    "                name = 'location Event Starts',\n",
    "                line = dict(\n",
    "                    shape = 'hvh',\n",
    "                    color = ('rgba(0, 204, 0, .05)'),\n",
    "                    width = 4))\n",
    "\n",
    "trace2 = go.Scatter(x = new_x, \n",
    "                y = all_story_priors[key][:,3], \n",
    "                mode = 'lines+markers', \n",
    "                name = 'social Event Starts',\n",
    "                line = dict(\n",
    "                    shape = 'hvh',\n",
    "                    color = ('rgba(255, 91, 71, .05)'),\n",
    "                    width = 4))\n",
    "\n",
    "trace3 = go.Scatter(x = new_x, \n",
    "                    y = loc_percent_story_keys[key], \n",
    "                    mode = 'lines+markers', \n",
    "                    name = 'participant w location',\n",
    "                    line = dict(\n",
    "                        shape = 'hvh',\n",
    "                        color = ('rgba(0, 191, 255, .5)'),\n",
    "                        width = 4))\n",
    "\n",
    "trace4 = go.Scatter(x = new_x, \n",
    "                    y = soc_percent_story_keys[key], \n",
    "                    mode = 'lines+markers', \n",
    "                    name = 'participants w social',\n",
    "                    line = dict(\n",
    "                        shape = 'hvh',\n",
    "                        color = ('rgba(255, 215, 0, .5)'),\n",
    "                        width = 4))\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    title= key,\n",
    "    xaxis=dict(\n",
    "        title='Sentence Number',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f')\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=False,\n",
    "        zeroline=False,\n",
    "        showline=False,\n",
    "        ticks='',\n",
    "        showticklabels=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "loc: 0.19955380489428873\n",
      "soc: 0.1577916642824127\n",
      "31\n",
      "loc: 0.3445297430531166\n",
      "soc: 0.3302002762169798\n",
      "43\n",
      "loc: 0.16839215754740292\n",
      "soc: 0.3545245679456396\n",
      "24\n",
      "loc: 0.14463698498546107\n",
      "soc: 0.2336487172178229\n",
      "23\n",
      "loc: 0.306308013876848\n",
      "soc: 0.20985257489672077\n",
      "11\n",
      "loc: 0.37711864406779627\n",
      "soc: 0.21468811705803534\n",
      "32\n",
      "loc: 0.27504899982976055\n",
      "soc: 0.1433510385893565\n",
      "44\n",
      "loc: 0.5805339172842425\n",
      "soc: 0.16894675451510968\n",
      "21\n",
      "loc: 0.3825291232432217\n",
      "soc: 0.24042685608175898\n",
      "33\n",
      "loc: 0.10887759855396663\n",
      "soc: 0.11916350888251724\n",
      "42\n",
      "loc: 0.16630071268405713\n",
      "soc: 0.19523681250099525\n",
      "14\n",
      "loc: 0.4747213305872215\n",
      "soc: 0.46291855274635\n",
      "13\n",
      "loc: 0.2552259519638095\n",
      "soc: 0.18156825980064079\n",
      "41\n",
      "loc: 0.25948586451929634\n",
      "soc: 0.1932993111817978\n",
      "34\n",
      "loc: 0.2405991214759391\n",
      "soc: 0.21484985796747316\n",
      "22\n",
      "loc: 0.2721265884378497\n",
      "soc: 0.09966453255402896\n"
     ]
    }
   ],
   "source": [
    "#find the mean correlation of the responses of participants with the same schema for each story and store the\n",
    "#value in a dictionary\n",
    "soc_cor = dict()\n",
    "loc_cor = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    z = len(soc_story_keys[key][0])\n",
    "    soc_this = np.nanmean(np.corrcoef(soc_story_keys[key].T)[np.triu(np.ones((z,z), dtype=np.bool),1)])\n",
    "    soc_cor[key] = soc_this\n",
    "    g = len(loc_story_keys[key][0])\n",
    "    loc_this = np.nanmean(np.corrcoef(loc_story_keys[key].T)[np.triu(np.ones((g,g), dtype=np.bool),1)])\n",
    "    loc_cor[key] = loc_this\n",
    "    \n",
    "\n",
    "for key in soc_cor:\n",
    "    print(key)\n",
    "    print('loc:', loc_cor[key])\n",
    "    print('soc:', soc_cor[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36012283858321603\n"
     ]
    }
   ],
   "source": [
    "#find the averages of correlations across location schemas\n",
    "\n",
    "loc_this_sum = loc_cor['14'] + loc_cor['24'] + loc_cor['34'] + loc_cor['44']\n",
    "mean_loc = loc_this_sum/4\n",
    "print(mean_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22800186153588556\n"
     ]
    }
   ],
   "source": [
    "#find the averages of correlations across social schemas\n",
    "\n",
    "soc_this_sum = soc_cor['41'] + soc_cor['42'] + soc_cor['43'] + soc_cor['44']\n",
    "mean_soc = soc_this_sum/4\n",
    "print(mean_soc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12': 0.25664832661326425, '31': 0.38817565595027176, '43': 0.20043573877826265, '24': 0.15119165888307928, '23': 0.19438594801316078, '11': 0.24783198743442642, '32': 0.11318534025583046, '44': 0.17222516231954957, '21': 0.34683027578511294, '33': 0.18540924799423916, '42': 0.15655942054250466, '14': 0.4198602962574182, '13': 0.23352754960792155, '41': 0.20204691261880536, '34': 0.17746907126500122, '22': 0.16184556064948866}\n"
     ]
    }
   ],
   "source": [
    "#correlation across the schemas \n",
    "isc_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    z = len(soc_story_keys[key][0])\n",
    "    x = len(loc_story_keys[key][0])\n",
    "    new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "    #permute new\n",
    "    coef_matrix = np.corrcoef(new.T)\n",
    "    this = coef_matrix[0:z,z:(z+x)]\n",
    "    mean_isc = np.nanmean(this)\n",
    "    isc_dict[key] = mean_isc\n",
    "    \n",
    "print(isc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12': -0.07056617998087097, '31': -0.04503263549420061, '43': 0.11272607130110207, '24': 0.059032918273595775, '23': 0.08080740812816223, '11': -0.022991962438281083, '32': 0.040296310736634006, '44': 0.16135645730321332, '21': -0.06580277194293604, '33': -0.06724114978867843, '42': 0.02710295203171534, '14': 0.04643047872918077, '13': 0.019707653919045554, '41': 0.05234767856683725, '34': 0.0611493376333635, '22': 0.07195612648084526}\n",
      "soc/soc + loc/loc cor - soc/loc cor 0.028829918341170498\n"
     ]
    }
   ],
   "source": [
    "#SFN ABSTRACT ANALYSIS 2 4.30.19\n",
    "#ANALYSIS 001\n",
    "#AVG CORRELATION OF KEY PRESSES OF SOCIAL-PRIMED PARTICIPANTS - AVG CORRELATION OF KEY PRESSES OF SOCIAL + LOCATION \n",
    "#PRIMED PARTICIPANTS\n",
    "#AVG OF SAME PRIMED PARTICIPANTS IS COMPUTED ONCE AT THE END, NOT TWICE, FIRST FOR EACH GROUP, THEN ACROSS SOCIAL\n",
    "#AND LOCATION\n",
    "\n",
    "correl_dif_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    z = len(soc_story_keys[key][0])\n",
    "    x = len(loc_story_keys[key][0])\n",
    "    new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "    coef_matrix = np.corrcoef(new.T)\n",
    "    this = coef_matrix[0:z,z:(z+x)]\n",
    "    mean_isc = np.nanmean(this)\n",
    "    soc_correl = coef_matrix[0:z, 0:z][np.triu(np.ones((z,z), dtype=np.bool),1)]\n",
    "    loc_correl = coef_matrix[z:(z+x), z:(z+x)][np.triu(np.ones((x,x), dtype=np.bool),1)]\n",
    "    correls= np.concatenate((soc_correl, loc_correl), axis = None)\n",
    "    mean_correl = np.nanmean(correls)\n",
    "    story_value = mean_correl - mean_isc\n",
    "    correl_dif_dict[key] = story_value\n",
    "    \n",
    "\n",
    "print(correl_dif_dict)\n",
    "print('soc/soc + loc/loc cor - soc/loc cor', np.array(list(correl_dif_dict.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "new [[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "coef matrix\n",
      "\n",
      "\n",
      " [[ 1.          0.30949223  0.30949223  0.21821789  0.46225016  0.23354968\n",
      "   0.33333333  0.65465367  0.43643578  0.21821789  0.2773501   0.21821789]\n",
      " [ 0.30949223  1.         -0.10344828  0.20261022  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.52678658  0.20261022  0.12017278  0.20261022]\n",
      " [ 0.30949223 -0.10344828  1.         -0.12156613  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.20261022 -0.12156613  0.66953406 -0.12156613]\n",
      " [ 0.21821789  0.20261022 -0.12156613  1.          0.06052275  0.15289416\n",
      "   0.          0.42857143  0.14285714  0.14285714 -0.18156826  0.71428571]\n",
      " [ 0.46225016  0.12017278  0.12017278  0.06052275  1.          0.36705849\n",
      "   0.46225016  0.54470478  0.54470478  0.30261377 -0.02564103 -0.18156826]\n",
      " [ 0.23354968  0.24575816  0.24575816  0.15289416  0.36705849  1.\n",
      "   0.38924947  0.35675303  0.15289416  0.15289416  0.19432508 -0.05096472]\n",
      " [ 0.33333333  0.30949223  0.30949223  0.          0.46225016  0.38924947\n",
      "   1.          0.43643578  0.43643578  0.21821789  0.2773501   0.        ]\n",
      " [ 0.65465367  0.20261022  0.20261022  0.42857143  0.54470478  0.35675303\n",
      "   0.43643578  1.          0.42857143  0.42857143  0.06052275  0.14285714]\n",
      " [ 0.43643578  0.52678658  0.20261022  0.14285714  0.54470478  0.15289416\n",
      "   0.43643578  0.42857143  1.          0.14285714  0.30261377  0.14285714]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.14285714  0.30261377  0.15289416\n",
      "   0.21821789  0.42857143  0.14285714  1.          0.06052275 -0.14285714]\n",
      " [ 0.2773501   0.12017278  0.66953406 -0.18156826 -0.02564103  0.19432508\n",
      "   0.2773501   0.06052275  0.30261377  0.06052275  1.          0.06052275]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.71428571 -0.18156826 -0.05096472\n",
      "   0.          0.14285714  0.14285714 -0.14285714  0.06052275  1.        ]]\n",
      "-0.07056617998087097\n",
      "0.0288299183411705\n",
      "{}\n",
      "12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "coef matrix\n",
      "\n",
      "\n",
      " [[ 1.          0.30949223  0.30949223  0.21821789  0.46225016  0.23354968\n",
      "   0.33333333  0.65465367  0.43643578  0.21821789  0.2773501   0.21821789]\n",
      " [ 0.30949223  1.         -0.10344828  0.20261022  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.52678658  0.20261022  0.12017278  0.20261022]\n",
      " [ 0.30949223 -0.10344828  1.         -0.12156613  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.20261022 -0.12156613  0.66953406 -0.12156613]\n",
      " [ 0.21821789  0.20261022 -0.12156613  1.          0.06052275  0.15289416\n",
      "   0.          0.42857143  0.14285714  0.14285714 -0.18156826  0.71428571]\n",
      " [ 0.46225016  0.12017278  0.12017278  0.06052275  1.          0.36705849\n",
      "   0.46225016  0.54470478  0.54470478  0.30261377 -0.02564103 -0.18156826]\n",
      " [ 0.23354968  0.24575816  0.24575816  0.15289416  0.36705849  1.\n",
      "   0.38924947  0.35675303  0.15289416  0.15289416  0.19432508 -0.05096472]\n",
      " [ 0.33333333  0.30949223  0.30949223  0.          0.46225016  0.38924947\n",
      "   1.          0.43643578  0.43643578  0.21821789  0.2773501   0.        ]\n",
      " [ 0.65465367  0.20261022  0.20261022  0.42857143  0.54470478  0.35675303\n",
      "   0.43643578  1.          0.42857143  0.42857143  0.06052275  0.14285714]\n",
      " [ 0.43643578  0.52678658  0.20261022  0.14285714  0.54470478  0.15289416\n",
      "   0.43643578  0.42857143  1.          0.14285714  0.30261377  0.14285714]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.14285714  0.30261377  0.15289416\n",
      "   0.21821789  0.42857143  0.14285714  1.          0.06052275 -0.14285714]\n",
      " [ 0.2773501   0.12017278  0.66953406 -0.18156826 -0.02564103  0.19432508\n",
      "   0.2773501   0.06052275  0.30261377  0.06052275  1.          0.06052275]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.71428571 -0.18156826 -0.05096472\n",
      "   0.          0.14285714  0.14285714 -0.14285714  0.06052275  1.        ]]\n",
      "-0.07056617998087097\n",
      "0.028829918341170477\n",
      "{}\n",
      "12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "coef matrix\n",
      "\n",
      "\n",
      " [[ 1.          0.30949223  0.30949223  0.21821789  0.46225016  0.23354968\n",
      "   0.33333333  0.65465367  0.43643578  0.21821789  0.2773501   0.21821789]\n",
      " [ 0.30949223  1.         -0.10344828  0.20261022  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.52678658  0.20261022  0.12017278  0.20261022]\n",
      " [ 0.30949223 -0.10344828  1.         -0.12156613  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.20261022 -0.12156613  0.66953406 -0.12156613]\n",
      " [ 0.21821789  0.20261022 -0.12156613  1.          0.06052275  0.15289416\n",
      "   0.          0.42857143  0.14285714  0.14285714 -0.18156826  0.71428571]\n",
      " [ 0.46225016  0.12017278  0.12017278  0.06052275  1.          0.36705849\n",
      "   0.46225016  0.54470478  0.54470478  0.30261377 -0.02564103 -0.18156826]\n",
      " [ 0.23354968  0.24575816  0.24575816  0.15289416  0.36705849  1.\n",
      "   0.38924947  0.35675303  0.15289416  0.15289416  0.19432508 -0.05096472]\n",
      " [ 0.33333333  0.30949223  0.30949223  0.          0.46225016  0.38924947\n",
      "   1.          0.43643578  0.43643578  0.21821789  0.2773501   0.        ]\n",
      " [ 0.65465367  0.20261022  0.20261022  0.42857143  0.54470478  0.35675303\n",
      "   0.43643578  1.          0.42857143  0.42857143  0.06052275  0.14285714]\n",
      " [ 0.43643578  0.52678658  0.20261022  0.14285714  0.54470478  0.15289416\n",
      "   0.43643578  0.42857143  1.          0.14285714  0.30261377  0.14285714]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.14285714  0.30261377  0.15289416\n",
      "   0.21821789  0.42857143  0.14285714  1.          0.06052275 -0.14285714]\n",
      " [ 0.2773501   0.12017278  0.66953406 -0.18156826 -0.02564103  0.19432508\n",
      "   0.2773501   0.06052275  0.30261377  0.06052275  1.          0.06052275]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.71428571 -0.18156826 -0.05096472\n",
      "   0.          0.14285714  0.14285714 -0.14285714  0.06052275  1.        ]]\n",
      "-0.07056617998087097\n",
      "0.028829918341170477\n",
      "{}\n",
      "12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "coef matrix\n",
      "\n",
      "\n",
      " [[ 1.          0.30949223  0.30949223  0.21821789  0.46225016  0.23354968\n",
      "   0.33333333  0.65465367  0.43643578  0.21821789  0.2773501   0.21821789]\n",
      " [ 0.30949223  1.         -0.10344828  0.20261022  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.52678658  0.20261022  0.12017278  0.20261022]\n",
      " [ 0.30949223 -0.10344828  1.         -0.12156613  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.20261022 -0.12156613  0.66953406 -0.12156613]\n",
      " [ 0.21821789  0.20261022 -0.12156613  1.          0.06052275  0.15289416\n",
      "   0.          0.42857143  0.14285714  0.14285714 -0.18156826  0.71428571]\n",
      " [ 0.46225016  0.12017278  0.12017278  0.06052275  1.          0.36705849\n",
      "   0.46225016  0.54470478  0.54470478  0.30261377 -0.02564103 -0.18156826]\n",
      " [ 0.23354968  0.24575816  0.24575816  0.15289416  0.36705849  1.\n",
      "   0.38924947  0.35675303  0.15289416  0.15289416  0.19432508 -0.05096472]\n",
      " [ 0.33333333  0.30949223  0.30949223  0.          0.46225016  0.38924947\n",
      "   1.          0.43643578  0.43643578  0.21821789  0.2773501   0.        ]\n",
      " [ 0.65465367  0.20261022  0.20261022  0.42857143  0.54470478  0.35675303\n",
      "   0.43643578  1.          0.42857143  0.42857143  0.06052275  0.14285714]\n",
      " [ 0.43643578  0.52678658  0.20261022  0.14285714  0.54470478  0.15289416\n",
      "   0.43643578  0.42857143  1.          0.14285714  0.30261377  0.14285714]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.14285714  0.30261377  0.15289416\n",
      "   0.21821789  0.42857143  0.14285714  1.          0.06052275 -0.14285714]\n",
      " [ 0.2773501   0.12017278  0.66953406 -0.18156826 -0.02564103  0.19432508\n",
      "   0.2773501   0.06052275  0.30261377  0.06052275  1.          0.06052275]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.71428571 -0.18156826 -0.05096472\n",
      "   0.          0.14285714  0.14285714 -0.14285714  0.06052275  1.        ]]\n",
      "-0.07056617998087097\n",
      "0.028829918341170498\n",
      "{}\n",
      "12 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "coef matrix\n",
      "\n",
      "\n",
      " [[ 1.          0.30949223  0.30949223  0.21821789  0.46225016  0.23354968\n",
      "   0.33333333  0.65465367  0.43643578  0.21821789  0.2773501   0.21821789]\n",
      " [ 0.30949223  1.         -0.10344828  0.20261022  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.52678658  0.20261022  0.12017278  0.20261022]\n",
      " [ 0.30949223 -0.10344828  1.         -0.12156613  0.12017278  0.24575816\n",
      "   0.30949223  0.20261022  0.20261022 -0.12156613  0.66953406 -0.12156613]\n",
      " [ 0.21821789  0.20261022 -0.12156613  1.          0.06052275  0.15289416\n",
      "   0.          0.42857143  0.14285714  0.14285714 -0.18156826  0.71428571]\n",
      " [ 0.46225016  0.12017278  0.12017278  0.06052275  1.          0.36705849\n",
      "   0.46225016  0.54470478  0.54470478  0.30261377 -0.02564103 -0.18156826]\n",
      " [ 0.23354968  0.24575816  0.24575816  0.15289416  0.36705849  1.\n",
      "   0.38924947  0.35675303  0.15289416  0.15289416  0.19432508 -0.05096472]\n",
      " [ 0.33333333  0.30949223  0.30949223  0.          0.46225016  0.38924947\n",
      "   1.          0.43643578  0.43643578  0.21821789  0.2773501   0.        ]\n",
      " [ 0.65465367  0.20261022  0.20261022  0.42857143  0.54470478  0.35675303\n",
      "   0.43643578  1.          0.42857143  0.42857143  0.06052275  0.14285714]\n",
      " [ 0.43643578  0.52678658  0.20261022  0.14285714  0.54470478  0.15289416\n",
      "   0.43643578  0.42857143  1.          0.14285714  0.30261377  0.14285714]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.14285714  0.30261377  0.15289416\n",
      "   0.21821789  0.42857143  0.14285714  1.          0.06052275 -0.14285714]\n",
      " [ 0.2773501   0.12017278  0.66953406 -0.18156826 -0.02564103  0.19432508\n",
      "   0.2773501   0.06052275  0.30261377  0.06052275  1.          0.06052275]\n",
      " [ 0.21821789  0.20261022 -0.12156613  0.71428571 -0.18156826 -0.05096472\n",
      "   0.          0.14285714  0.14285714 -0.14285714  0.06052275  1.        ]]\n",
      "-0.07056617998087097\n",
      "0.02882991834117048\n",
      "{'12': -0.07056617998087097, '31': -0.04503263549420072, '43': 0.11272607130110207, '24': 0.05903291827359572, '23': 0.08080740812816228, '11': -0.02299196243828114, '32': 0.040296310736634006, '44': 0.16135645730321319, '21': -0.06580277194293604, '33': -0.0672411497886784, '42': 0.027102952031715366, '14': 0.04643047872918071, '13': 0.01970765391904561, '41': 0.05234767856683725, '34': 0.0611493376333635, '22': 0.07195612648084526}\n",
      "soc/soc + loc/loc cor - soc/loc cor 0.02882991834117048\n"
     ]
    }
   ],
   "source": [
    "#SFN ABSTRACT ANALYSIS 2 4.30.19\n",
    "#ANALYSIS 002\n",
    "#PERMUTATION: AVG CORRELATION OF KEY PRESSES OF SOCIAL-PRIMED PARTICIPANTS - AVG CORRELATION OF KEY PRESSES OF SOCIAL + LOCATION \n",
    "#PRIMED PARTICIPANTS\n",
    "#AVG OF SAME PRIMED PARTICIPANTS IS COMPUTED ONCE AT THE END, NOT TWICE, FIRST FOR EACH GROUP, THEN ACROSS SOCIAL\n",
    "#AND LOCATION\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 5):\n",
    "    correl_dif_dict = dict()\n",
    "    print(correl_dif_dict)\n",
    "    for key in soc_story_keys:\n",
    "        z = len(soc_story_keys[key][0])\n",
    "        x = len(loc_story_keys[key][0])\n",
    "        new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "        if key == '12' and i == 0:\n",
    "            print('new', new)\n",
    "        #permute new\n",
    "        this_perm = np.random.permutation(new)\n",
    "        if key == '12':\n",
    "            print(key, '\\n\\n\\n\\n\\n', this_perm)\n",
    "        coef_matrix = np.corrcoef(this_perm.T)\n",
    "        if key == '12':\n",
    "            print('coef matrix\\n\\n\\n', coef_matrix)\n",
    "        this = coef_matrix[0:z,z:(z+x)]\n",
    "        mean_isc = np.nanmean(this)\n",
    "        soc_correl = coef_matrix[0:z, 0:z][np.triu(np.ones((z,z), dtype=np.bool),1)]\n",
    "        loc_correl = coef_matrix[z:(z+x), z:(z+x)][np.triu(np.ones((x,x), dtype=np.bool),1)]\n",
    "        correls= np.concatenate((soc_correl, loc_correl), axis = None)\n",
    "        mean_correl = np.nanmean(correls)\n",
    "        story_value = mean_correl - mean_isc\n",
    "        correl_dif_dict[key] = story_value\n",
    "    print(correl_dif_dict['12'])\n",
    "    this_avg = np.array(list(correl_dif_dict.values())).mean()\n",
    "    print(this_avg)\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "print(correl_dif_dict)\n",
    "print('soc/soc + loc/loc cor - soc/loc cor', np.array(list(correl_dif_dict.values())).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1577916642824127 soc_cor\n",
      "0.25664832661326425 isc_cor\n",
      "0.3302002762169798 soc_cor\n",
      "0.38817565595027176 isc_cor\n",
      "0.3545245679456396 soc_cor\n",
      "0.20043573877826265 isc_cor\n",
      "0.2336487172178229 soc_cor\n",
      "0.15119165888307928 isc_cor\n",
      "0.20985257489672077 soc_cor\n",
      "0.19438594801316078 isc_cor\n",
      "0.21468811705803534 soc_cor\n",
      "0.24783198743442642 isc_cor\n",
      "0.1433510385893565 soc_cor\n",
      "0.11318534025583046 isc_cor\n",
      "0.16894675451510968 soc_cor\n",
      "0.17222516231954957 isc_cor\n",
      "0.24042685608175898 soc_cor\n",
      "0.34683027578511294 isc_cor\n",
      "0.11916350888251724 soc_cor\n",
      "0.18540924799423916 isc_cor\n",
      "0.19523681250099525 soc_cor\n",
      "0.15655942054250466 isc_cor\n",
      "0.46291855274635 soc_cor\n",
      "0.4198602962574182 isc_cor\n",
      "0.18156825980064079 soc_cor\n",
      "0.23352754960792155 isc_cor\n",
      "0.1932993111817978 soc_cor\n",
      "0.20204691261880536 isc_cor\n",
      "0.21484985796747316 soc_cor\n",
      "0.17746907126500122 isc_cor\n",
      "0.09966453255402896 soc_cor\n",
      "0.16184556064948866 isc_cor\n",
      "{'12': -0.07797559202491355, '31': -0.05081064631522353, '43': 0.06102262396825858, '24': 0.03795119221856269, '23': 0.06369434637362359, '11': 0.048071393128489404, '32': 0.09601467895372806, '44': 0.20251517358012652, '21': -0.03535228612262259, '33': -0.07138869427599723, '42': 0.024209342050021537, '14': 0.048959645409367536, '13': -0.015130443725696413, '41': 0.024345675231741692, '34': 0.05025541845670489, '22': 0.024049999846450676}\n",
      "soc/soc + loc/loc cor - soc/loc cor 0.02690198917203887\n"
     ]
    }
   ],
   "source": [
    "#SFN ABSTRACT ANALYSIS 1 4.29.19\n",
    "#NOT USING\n",
    "#AVG CORRELATION OF KEY PRESSES OF SOCIAL-PRIMED PARTICIPANTS - AVG CORRELATION OF KEY PRESSES OF SOCIAL + LOCATION \n",
    "#PRIMED PARTICIPANTS\n",
    "cor_this = dict()\n",
    "\n",
    "\n",
    "for key in isc_dict:\n",
    "    print(soc_cor[key], 'soc_cor')\n",
    "    print(isc_dict[key], 'isc_cor')\n",
    "    s = (soc_cor[key] + loc_cor[key])/2 - isc_dict[key]\n",
    "    cor_this[key] = s\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print(cor_this)\n",
    "print('soc/soc + loc/loc cor - soc/loc cor', np.array(list(cor_this.values())).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7e053627ad17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_story_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#concatenate key presses w a priori boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0msoc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#generate correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#CORRELATION BETWEEN SOCIAL PRIMED RESPONSES/A PRIORI SOCIAL BOUNDARIES - LOCATION PRIMED RESPONSES/A PRIORI SOCIAL BOUNDARIES\n",
    "#CORRELATION BETWEEN LOCATION PRIMED RESPONSES/A PRIORI LOCATION BOUNDARIES - SOCIAL PRIMED RESPONSES/A PRIORI LOCATION BOUNDARIES\n",
    "#SFN analysis 4.29.19\n",
    "#find the correlation between all participants' event boundaries and a priori boundaries\n",
    "soc_a_priori_corr_dict = dict()\n",
    "loc_a_priori_corr_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    #concatenate the key presses for social and location primed participants for each story\n",
    "    new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "    #make a priori boundaries into columns\n",
    "    loc = [[i] for i in all_story_priors[key][:,2]]\n",
    "    soc = [[i] for i in all_story_priors[key][:,3]]\n",
    "    #concatenate key presses w a priori boundaries\n",
    "    loc_new = np.hstack((loc_story_keys[key], loc))\n",
    "    soc_new = np.hstack((soc_story_keys[key], soc))\n",
    "    #generate correlation matrix\n",
    "    loc_coef_matrix = np.corrcoef(loc_new.T)\n",
    "    soc_coef_matrix = np.corrcoef(soc_new.T)\n",
    "    #take the last row\n",
    "    loc_line = loc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    soc_line = soc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    #remove the last element\n",
    "    loc_record = loc_line[:-1]\n",
    "    soc_record = soc_line[:-1]\n",
    "    #average the values\n",
    "    avg_loc = np.nanmean(loc_record)\n",
    "    avg_soc = np.nanmean(soc_record)\n",
    "    #put in the dictionary\n",
    "    a_priori_corr_dict[key] = [avg_loc, avg_soc]\n",
    "\n",
    "    \n",
    "a_priori_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [1.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]] 59\n",
      "[[1. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]] 63\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2400be7c555a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'11'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'12'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "loc = [[i] for i in all_story_priors['11'][:,2]]\n",
    "print(loc, len(loc))\n",
    "print(loc_story_keys['11'], len(loc_story_keys['11']))\n",
    "loc_new = np.hstack((loc_story_keys['12'], loc))\n",
    "print(loc_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a806a4e90d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_story_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#concatenate key presses w a priori boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msoc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#generate correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#I THINK THIS IS A BAD ANALYSIS BC I SHOULD ONLY BE CORRELATION THE A PRIORI BOUNDARIES OF SOCIAL SCRIPT TO SOCIAL PRIMED \n",
    "#PARTICIPANTS\n",
    "#find the correlation between all participants' event boundaries and a priori boundaries\n",
    "a_priori_corr_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    #concatenate the key presses for social and location primed participants for each story\n",
    "    new = np.concatenate((soc_story_keys[key], loc_story_keys[key]), axis = 1)\n",
    "    #make a priori boundaries into columns\n",
    "    loc = [[i] for i in all_story_priors[key][:,2]]\n",
    "    soc = [[i] for i in all_story_priors[key][:,3]]\n",
    "    #concatenate key presses w a priori boundaries\n",
    "    loc_new = np.hstack((new, loc))\n",
    "    soc_new = np.hstack((new, soc))\n",
    "    #generate correlation matrix\n",
    "    loc_coef_matrix = np.corrcoef(loc_new.T)\n",
    "    soc_coef_matrix = np.corrcoef(soc_new.T)\n",
    "    #take the last row\n",
    "    loc_line = loc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    soc_line = soc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    #remove the last element\n",
    "    loc_record = loc_line[:-1]\n",
    "    soc_record = soc_line[:-1]\n",
    "    #average the values\n",
    "    avg_loc = np.nanmean(loc_record)\n",
    "    avg_soc = np.nanmean(soc_record)\n",
    "    #put in the dictionary\n",
    "    a_priori_corr_dict[key] = [avg_loc, avg_soc]\n",
    "\n",
    "    \n",
    "a_priori_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b75c95929fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_story_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#concatenate key presses w a priori boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msoc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#generate correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#find the correlation between event boundaries of participants primed with location schemas and a priori boundaries\n",
    "loc_a_priori_corr_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    #make a priori boundaries into columns\n",
    "    loc = [[i] for i in all_story_priors[key][:,2]]\n",
    "    soc = [[i] for i in all_story_priors[key][:,3]]\n",
    "    #concatenate key presses w a priori boundaries\n",
    "    loc_new = np.hstack((loc_story_keys[key], loc))\n",
    "    soc_new = np.hstack((loc_story_keys[key], soc))\n",
    "    #generate correlation matrix\n",
    "    loc_coef_matrix = np.corrcoef(loc_new.T)\n",
    "    soc_coef_matrix = np.corrcoef(soc_new.T)\n",
    "    #take the last row\n",
    "    loc_line = loc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    soc_line = soc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    #remove the last element\n",
    "    loc_record = loc_line[:-1]\n",
    "    soc_record = soc_line[:-1]\n",
    "    #average the values\n",
    "    avg_loc = np.nanmean(loc_record)\n",
    "    avg_soc = np.nanmean(soc_record)\n",
    "    #put in the dictionary\n",
    "    loc_a_priori_corr_dict[key] = [avg_loc, avg_soc]\n",
    "\n",
    "    \n",
    "loc_a_priori_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-dd8337efb425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_story_priors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#concatenate key presses w a priori boundaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msoc_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoc_story_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'41'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#find the correlation between event boundaries of participants primed with social schemas and a priori boundaries\n",
    "soc_a_priori_corr_dict = dict()\n",
    "\n",
    "for key in soc_story_keys:\n",
    "    #make a priori boundaries into columns\n",
    "    loc = [[i] for i in all_story_priors[key][:,2]]\n",
    "    soc = [[i] for i in all_story_priors[key][:,3]]\n",
    "    #concatenate key presses w a priori boundaries\n",
    "    loc_new = np.hstack((soc_story_keys[key], loc))\n",
    "    soc_new = np.hstack((soc_story_keys[key], soc))\n",
    "    if key == '41':\n",
    "        print(soc_new)\n",
    "    #generate correlation matrix\n",
    "    loc_coef_matrix = np.corrcoef(loc_new.T)\n",
    "    soc_coef_matrix = np.corrcoef(soc_new.T)\n",
    "    #take the last row\n",
    "    loc_line = loc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    soc_line = soc_coef_matrix[(len(loc_coef_matrix) - 1), :]\n",
    "    #remove the last element\n",
    "    loc_record = loc_line[:-1]\n",
    "    soc_record = soc_line[:-1]\n",
    "    #average the values\n",
    "    avg_loc = np.nanmean(loc_record)\n",
    "    avg_soc = np.nanmean(soc_record)\n",
    "    #put in the dictionary\n",
    "    soc_a_priori_corr_dict[key] = [avg_loc, avg_soc]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot all the correlation values for each story together\n",
    "\n",
    "for key in a_priori_corr_dict:\n",
    "    these_labels = ['all;loc', 'all;soc', 'loc-primed;loc', 'loc-primed;soc', 'soc-primed;loc', 'soc-primed;soc','cor-within loc', 'cor-within soc', 'cor across schemas']\n",
    "    x_pos = np.arange(len(these_labels))\n",
    "    x, y = a_priori_corr_dict[key]\n",
    "    a, b = loc_a_priori_corr_dict[key]\n",
    "    c, d = soc_a_priori_corr_dict[key]\n",
    "    e = loc_cor[key]\n",
    "    f = soc_cor[key]\n",
    "    g = isc_dict[key]\n",
    "    print(x)\n",
    "    these_values = [x, y, a, b, c, d, e, f, g]\n",
    "    print(these_values)\n",
    "    plt.figure()\n",
    "    plt.figure(figsize = (15,5))\n",
    "    plt.bar(x_pos, these_values, align='center', alpha=0.5)\n",
    "    plt.xticks(x_pos, these_labels)\n",
    "    plt.ylim([0,0.6])\n",
    "    plt.ylabel('Corr')\n",
    "    plt.title(key + ' Correlations')\n",
    "    plt.savefig('correlation_figs/'+key+'correlation_bar_graphs.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
