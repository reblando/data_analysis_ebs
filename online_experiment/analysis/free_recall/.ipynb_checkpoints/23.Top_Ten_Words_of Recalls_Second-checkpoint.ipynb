{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Top Ten Words of Recall words for each regressor\n",
    "### For each story there will be 3 'Top Ten Words', One for each type of regressor\n",
    "#### 1) Concatenate unique words across all participants\n",
    "#### 2) For each regressor, regress out of the words the other two vectors. \n",
    "#### 3) Correlate the residual wvs with the target regressor. \n",
    "#### 4) Index the 10 highest values, and find the 10 highest words\n",
    "#### 5) Put in dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import copy\n",
    "from random import randrange\n",
    "from sklearn.metrics import jaccard_score\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA #for cluster analysis\n",
    "from gensim.models import KeyedVectors #for word embeddings\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import os #for importing\n",
    "import pickle #for loading transcripts\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "# from _DRAFT_20200604_functions import * #includes constants and score function\n",
    "from tqdm import tqdm_notebook #for progress bar\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import recalls, and uncentered story and template vectors and sums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import recalls and sums\n",
    "recalls = pickle.load( open( 'fr_recalls', \"rb\" ) )\n",
    "sums = pickle.load( open( \"fr_sums\", \"rb\" ) )\n",
    "\n",
    "#import non-centered story, template\n",
    "templates = pickle.load( open( 'template_vectors', \"rb\" ) )\n",
    "stories = pickle.load( open( 'actual_story_vectors', \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipath = 'rolando/wiki-news-300d-1M.vec'\n",
    "wv_model = KeyedVectors.load_word2vec_format(wikipath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_dim = 300\n",
    "\n",
    "# FastText preprocessing, based on bittlingmayer/ft_wiki_preproc.py\n",
    "# Remove special characters, put spaces between all tokens\n",
    "SUB = [\"s/’/'/g\", \"s/′/'/g\", \"s/''/ /g\", \"s/'/ ' /g\", 's/“/\"/g', 's/”/\"/g', 's/\"/ /g', \"s/\\\\./ \\\\. /g\", \"s/<br \\\\/>/ /g\", \"s/, / , /g\", \"s/(/ ( /g\", \"s/)/ ) /g\", \"s/\\\\!/ \\\\! /g\", \"s/\\\\?/ \\\\? /g\", \"s/\\\\;/ /g\", \"s/\\\\:/ /g\", \"s/-/ - /g\", \"s/=/ /g\", \"s/=/ /g\", \"s/*/ /g\", \"s/|/ /g\", \"s/«/ /g\", \n",
    "       \"s/…/ /g\", \"s/‘/ /g\", \"s/í/ /g\", \"s/ñ/ /g\", \"s/\\x84/ /g\", \"s/î/ /g\", \"s/ó/ /g\", \"s/\\x83/ /g\", \"s/ï/ /g\", \"s/õ/ /g\",\n",
    "       \"s/ò/ /g\", \"s/,/ /g\", \"s/ô/ /g\", \"s/\\x92/ /g\", \"s/é/ /g\", \"s/\\x8e/ /g\", \"s/â\\x80¦/ /g\", \"s/\\x91/ /g\", \"s/\\x93/ /g\",\n",
    "       \"s/\\x94/ /g\", \"s/ã®/ /g\", \"s/ã¨/ /g\", \"s/ã©/ /g\",\n",
    "       \"s/\\â\\x80\\x99/ /g\", \"s/â\\x80\\x9c/ /g\", \"s/â\\x80\\x9d/ /g\", \"s/â\\x80\\x99/ /g\", \"s/â\\x80\\x9c/ /g\", \"s/â\\x80\\x98/ /g\",\n",
    "       \"s/â/ /g\"]\n",
    "\n",
    "def __normalize_text(s):\n",
    "    for sg in SUB:\n",
    "        rep = sg.replace('\\\\','').split('/')\n",
    "        s = s.replace(rep[1], rep[2])\n",
    "    s = s.replace('/',' ')\n",
    "    return s\n",
    "\n",
    "def __spaces(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def __digits(s):\n",
    "    return ''.join(filter(lambda c: not c.isdigit(), s))\n",
    "\n",
    "# def preproc(s):\n",
    "#     return __punctuation(__spaces(__digits(__normalize_text(s.lower()))))\n",
    "\n",
    "def preproc(s):\n",
    "    return (__spaces(__digits(__normalize_text(s.lower()))))\n",
    "\n",
    "def __punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def word2vecSent(sentence, model = 'fasttext'):\n",
    "    wv_dim = 300 #for glove and fasttext\n",
    "    \n",
    "    if model == 'glove':\n",
    "        wvmodel = glove_model\n",
    "    elif model == 'fasttext':\n",
    "        wvmodel = wv_model\n",
    "        \n",
    "    words = preproc(sentence).split(' ')\n",
    "    wv = np.zeros((len(words), wv_dim))\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in wvmodel.vocab:\n",
    "            wv[i,:] = wvmodel.word_vec(words[i])\n",
    "    \n",
    "    return words, wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. 3 sets of top ten \n",
    "## A. Find unique words in recalls of each story\n",
    "### 1. Concatenate words and word vectors in parallel across all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = {}\n",
    "all_wvs = {}\n",
    "\n",
    "#iterate through all recalls in a story and concatente words and wvs of all stories\n",
    "for key in recalls:\n",
    "    words = np.zeros((0,1))\n",
    "    wvs = np.zeros((0,300))\n",
    "    for i in range(0,3):\n",
    "        for j in range(0,len(recalls[key][i])):\n",
    "            p_words, p_wvs = word2vecSent(recalls[key][i][j][0])\n",
    "            # reshape p_words\n",
    "            p_words = np.array(p_words)\n",
    "            p_words = p_words.reshape(p_words.shape[0],-1)\n",
    "            # stack p_words and p_wvs\n",
    "            words = np.vstack((words, p_words))\n",
    "            wvs = np.vstack((wvs, p_wvs))\n",
    "    all_words[key] = words\n",
    "    all_wvs[key] = wvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Centering all words + story wvs + template wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all words from recall\n",
    "\n",
    "concat = np.zeros((0,300))\n",
    "\n",
    "for key in all_wvs:\n",
    "    for i in range(0, len(all_wvs[key])):\n",
    "        concat = np.vstack((concat, all_wvs[key][i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37545, 300)\n"
     ]
    }
   ],
   "source": [
    "print(concat.shape)\n",
    "for key in stories:\n",
    "    concat = np.vstack((concat, stories[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37561, 300)\n",
      "(37569, 300)\n"
     ]
    }
   ],
   "source": [
    "print(concat.shape)\n",
    "for key in templates:\n",
    "    concat = np.vstack((concat, templates[key]))\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "centering_vec = np.mean(concat, axis = 0)\n",
    "\n",
    "# template vectors\n",
    "\n",
    "for key in templates:\n",
    "    templates[key] = templates[key] - centering_vec\n",
    "    \n",
    "# recall vectors\n",
    "\n",
    "for key in recalls:\n",
    "    for i in range(0, len(all_wvs[key])):\n",
    "        all_wvs[key][i] = all_wvs[key][i] - centering_vec\n",
    "            \n",
    "#story vectors\n",
    "\n",
    "#make new dict with int key instead of string\n",
    "int_stories = {}\n",
    "for key in stories:\n",
    "    int_stories[int(key)] = stories[key] - centering_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find unique words and wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "au_words = {}\n",
    "au_wvs = {}\n",
    "\n",
    "for key in all_words:\n",
    "    # find unique wvs and their indices:\n",
    "    unique_wvs, index = np.unique(all_wvs[key], axis=0, return_index=True)\n",
    "    unique_words =  all_words[key][index]\n",
    "    # put in dicts\n",
    "    au_wvs[key] = unique_wvs\n",
    "    au_words[key] = unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. *Story* Top Ten\n",
    "### A. Regress out of all the unique_wvs the loc and soc template wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resid_wvs = {}\n",
    "\n",
    "for key in au_wvs:\n",
    "    these_residuals = np.zeros((0, 300))\n",
    "    loc = key%10\n",
    "    soc = round(key/10)*10\n",
    "    # Make the inputs of the regression\n",
    "    # location template\n",
    "    l_temp = templates[loc].reshape(templates[loc].shape[0],-1)\n",
    "    # social template\n",
    "    s_temp = templates[soc].reshape(templates[soc].shape[0],-1)\n",
    "    # Concatenating inputes\n",
    "    inputs = np.concatenate((l_temp, s_temp), axis = 1)\n",
    "    for i in range(0,len(au_wvs[key])):\n",
    "        output = np.copy(au_wvs[key][i])\n",
    "        #output = output.reshape(output.shape[0],-1)\n",
    "        model = LinearRegression().fit(inputs, output)\n",
    "        ## Is subtracting the intercept correct?? \n",
    "        new_vec = output - np.dot(model.coef_, inputs.T)- model.intercept_\n",
    "        these_residuals = np.vstack((these_residuals, new_vec))\n",
    "    resid_wvs[key] = these_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Correlate each wv in the recall with the story wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correls = {}\n",
    "\n",
    "for key in resid_wvs:\n",
    "    corr = np.zeros((0,1))\n",
    "    this_story = stories[str(key)].reshape(stories[str(key)].shape[0], -1)\n",
    "    for i in range(0, len(resid_wvs[key])):\n",
    "        this_wv = resid_wvs[key][i].reshape(resid_wvs[key][i].shape[0], -1)\n",
    "        this_correl = np.corrcoef(this_story.T, this_wv.T)\n",
    "        # add to corr\n",
    "        corr = np.vstack((corr, this_correl[0,1]))\n",
    "    all_correls[key] = corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Top Ten values' indices and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['hadn' 'could' 'might' 'wasn' 'don' 'can' 'doesn' 'hear' 'got' 'make']\n",
      "33\n",
      "['could' 'doesn' 'wasn' 'can' 'isn' 'should' 'would' 'make' 'extremely'\n",
      " 'knows']\n",
      "44\n",
      "['couldn' 'could' 'wasn' 'can' 'doesn' 'hasn' 'don' 'seeing' 'looked'\n",
      " 'nodded']\n",
      "23\n",
      "['could' 'didn' 'wasn' 'don' 'got' 'seeing' 'looked' 'cannot' 'knows'\n",
      " 'would']\n",
      "12\n",
      "['couldn' 'could' 'might' 'didn' 'can' 'don' 'doesn' 'slightly' 'ago'\n",
      " 'should']\n",
      "21\n",
      "['could' 'nodded' 'wasn' 'ago' 'can' 'make' 'always' 'gladly' 'looked'\n",
      " 'got']\n",
      "13\n",
      "['wouldn' 'could' 'might' 'wasn' 'didn' 'don' 'can' 'doesn' 'always'\n",
      " 'nodded']\n",
      "42\n",
      "['could' 'wouldn' 'might' 'hadn' 'slightly' 'can' 'doesn' 'got' 'shouldn'\n",
      " 'make']\n",
      "43\n",
      "['could' 'didn' 'sounded' 'got' 'feels' 'looked' 'looks' 'seeing' 'hear'\n",
      " 'would']\n",
      "32\n",
      "['could' 'didn' 'wasn' 'seeing' 'make' 'would' 'isn' 'got' 'amount' 'want']\n",
      "34\n",
      "['could' 'don' 'can' 'cannot' 'should' 'would' 'during' 'wants' 'amount'\n",
      " 'have']\n",
      "22\n",
      "['couldn' 'didn' 'hadn' 'wasn' 'onto' 'got' 'don' 'looked' 'make' 'hear']\n",
      "41\n",
      "['could' 'might' 'didn' 'seeing' 'laughed' 'got' 'greatly' 'getting'\n",
      " 'would' 'having']\n",
      "14\n",
      "['couldn' 'could' 'don' 'can' 'doesn' 'didn' 'shouldn' 'make' 'sorry'\n",
      " 'hear']\n",
      "24\n",
      "['can' 'during' 'ago' 'cannot' 'got' 'extremely' 'towards' 'knows' 'sorry'\n",
      " 'would']\n",
      "31\n",
      "['wouldn' 'could' 'don' 'can' 'make' 'somewhat' 'would' 'knows' 'want'\n",
      " 'looks']\n"
     ]
    }
   ],
   "source": [
    "for key in all_correls:\n",
    "    print(key)\n",
    "    this_corr = all_correls[key]\n",
    "    this_corr = np.ravel(this_corr)\n",
    "    story_index = this_corr.argsort()[-10:][::-1]\n",
    "    #print(story_index)\n",
    "    # index the top words\n",
    "    top_words = np.zeros((0,1))\n",
    "    for i in range(0, 10):\n",
    "        top_words = np.vstack((top_words, au_words[key][story_index[i]]))\n",
    "    top_words = top_words.ravel()\n",
    "    print(top_words)\n",
    "    top_ten[key] = {'story': top_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. *Location* Top Ten\n",
    "### 1. Regress out of all the unique_wvs the story and soc template wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resid_wvs = {}\n",
    "\n",
    "for key in au_wvs:\n",
    "    these_residuals = np.zeros((0, 300))\n",
    "    soc = round(key/10)*10\n",
    "    # Make the inputs of the regression\n",
    "    # story vector\n",
    "    story_vec = stories[str(key)].reshape(stories[str(key)].shape[0],-1)\n",
    "    # social template\n",
    "    s_temp = templates[soc].reshape(templates[soc].shape[0],-1)\n",
    "    # Concatenating inputes\n",
    "    inputs = np.concatenate((story_vec, s_temp), axis = 1)\n",
    "    for i in range(0,len(au_wvs[key])):\n",
    "        output = np.copy(au_wvs[key][i])\n",
    "        #output = output.reshape(output.shape[0],-1)\n",
    "        model = LinearRegression().fit(inputs, output)\n",
    "        ## Is subtracting the intercept correct?? \n",
    "        new_vec = output #- np.dot(model.coef_, inputs.T)- model.intercept_\n",
    "        these_residuals = np.vstack((these_residuals, new_vec))\n",
    "    resid_wvs[key] = these_residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Correlate each wv in the recall with the story wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correls = {}\n",
    "\n",
    "for key in resid_wvs:\n",
    "    corr = np.zeros((0,1))\n",
    "    loc = key%10\n",
    "    this_loc = templates[loc].reshape(templates[loc].shape[0], -1)\n",
    "    for i in range(0, len(resid_wvs[key])):\n",
    "        this_wv = resid_wvs[key][i].reshape(resid_wvs[key][i].shape[0], -1)\n",
    "        this_correl = np.corrcoef(this_loc.T, this_wv.T)\n",
    "        # add to corr\n",
    "        corr = np.vstack((corr, this_correl[0,1]))\n",
    "    all_correls[key] = corr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Top Ten values' indices and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "['restaurant' 'food' 'menus' 'menu' 'diner' 'restuarant' 'foods' 'meal'\n",
      " 'waiter' 'dessert']\n",
      "33\n",
      "['grocery' 'store' 'groceries' 'stores' 'supermarket' 'checkout' 'shop'\n",
      " 'checkouts' 'purchase' 'cashier']\n",
      "44\n",
      "['lecture' 'class' 'lectures' 'lecturing' 'classroom' 'assignment' 'hall'\n",
      " 'lesson' 'professor' 'lecturer']\n",
      "23\n",
      "['grocery' 'store' 'groceries' 'supermarket' 'checkout' 'shop' 'shopping'\n",
      " 'checkouts' 'grocer' 'shoppers']\n",
      "12\n",
      "['airport' 'airports' 'plane' 'flight' 'boarding' 'gate' 'gates'\n",
      " 'security' 'departure' 'terminal']\n",
      "21\n",
      "['restaurant' 'food' 'menus' 'menu' 'chef' 'dishes' 'meal' 'waiter'\n",
      " 'dessert' 'eating']\n",
      "13\n",
      "['grocery' 'store' 'groceries' 'checkout' 'shopping' 'cashier' 'items'\n",
      " 'cart' 'food' 'products']\n",
      "42\n",
      "['airport' 'plane' 'flight' 'boarding' 'gate' 'airplane' 'security'\n",
      " 'departure' 'planes' 'destination']\n",
      "43\n",
      "['grocery' 'store' 'groceries' 'supermarket' 'checkout' 'shop' 'shopping'\n",
      " 'warehouse' 'cashier' 'items']\n",
      "32\n",
      "['airport' 'plane' 'flight' 'gate' 'gates' 'flights' 'airplane' 'security'\n",
      " 'planes' 'departing']\n",
      "34\n",
      "['lecture' 'class' 'classes' 'lecturing' 'classroom' 'assignment' 'hall'\n",
      " 'lesson' 'professor' 'of']\n",
      "22\n",
      "['airport' 'plane' 'flight' 'boarding' 'gate' 'airplane' 'security'\n",
      " 'passenger' 'passengers' 'baggage']\n",
      "41\n",
      "['restaurant' 'food' 'menus' 'menu' 'dining' 'meals' 'meal' 'waiter'\n",
      " 'cafe' 'sushi']\n",
      "14\n",
      "['lecture' 'class' 'lectures' 'teaching' 'classroom' 'presentation' 'hall'\n",
      " 'semester' 'professor' 'lecturer']\n",
      "24\n",
      "['lecture' 'class' 'lectures' 'classroom' 'assignment' 'hall' 'lesson'\n",
      " 'semester' 'professor' 'lecturer']\n",
      "31\n",
      "['restaurant' 'food' 'menus' 'menu' 'restuarant' 'meals' 'meal' 'waiter'\n",
      " 'hotel' 'eating']\n"
     ]
    }
   ],
   "source": [
    "for key in all_correls:\n",
    "    print(key)\n",
    "    this_corr = all_correls[key]\n",
    "    this_corr = np.ravel(this_corr)\n",
    "    story_index = this_corr.argsort()[-10:][::-1]\n",
    "    #print(story_index)\n",
    "    # index the top words\n",
    "    top_words = np.zeros((0,1))\n",
    "    for i in range(0, 10):\n",
    "        top_words = np.vstack((top_words, au_words[key][story_index[i]]))\n",
    "    top_words = top_words.ravel()\n",
    "    print(top_words)\n",
    "    top_ten[key]['loc'] =  top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. *Social* Top Ten\n",
    "### 1. Regress out of all the unique_wvs the loc and soc template wvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_wvs = {}\n",
    "\n",
    "for key in au_wvs:\n",
    "    these_residuals = np.zeros((0, 300))\n",
    "    loc = key%10\n",
    "    # Make the inputs of the regression\n",
    "    # story vector\n",
    "    story_vec = stories[str(key)].reshape(stories[str(key)].shape[0],-1)\n",
    "    # location template\n",
    "    l_temp = templates[loc].reshape(templates[loc].shape[0],-1)\n",
    "    # Concatenating inputes\n",
    "    inputs = np.concatenate((story_vec, l_temp), axis = 1)\n",
    "    for i in range(0,len(au_wvs[key])):\n",
    "        output = np.copy(au_wvs[key][i])\n",
    "        #output = output.reshape(output.shape[0],-1)\n",
    "        model = LinearRegression().fit(inputs, output)\n",
    "        ## Is subtracting the intercept correct?? \n",
    "        new_vec = output - np.dot(model.coef_, inputs.T)- model.intercept_\n",
    "        these_residuals = np.vstack((these_residuals, new_vec))\n",
    "    resid_wvs[key] = these_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Correlate each wv in the recall with the social wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correls = {}\n",
    "\n",
    "for key in resid_wvs:\n",
    "    corr = np.zeros((0,1))\n",
    "    soc = round(key/10)*10\n",
    "    this_soc = templates[soc].reshape(templates[soc].shape[0], -1)\n",
    "    for i in range(0, len(resid_wvs[key])):\n",
    "        this_wv = resid_wvs[key][i].reshape(resid_wvs[key][i].shape[0], -1)\n",
    "        this_correl = np.corrcoef(this_soc.T, this_wv.T)\n",
    "        # add to corr\n",
    "        corr = np.vstack((corr, this_correl[0,1]))\n",
    "    all_correls[key] = corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Top Ten values' indices and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[471 162 233 264 445 211 462 109 297 307]\n",
      "['breakup' 'breaking' 'for' 'of' 'the' 'break' 'relationship' 'what'\n",
      " 'considering' 'ending']\n",
      "[256 310 144 273 442 108 416 472 457 471]\n",
      "['deal' 'partnership' 'business' 'agreement' 'investment' 'success' 'the'\n",
      " 'handshake' 'deals' 'competitor']\n",
      "[376 258 248 185  94 241 219 375 280 220]\n",
      "['the' 'two' 'first' 'other' 'what' 'couple' 'of' 'time' 'when' 'next']\n",
      "[395 364 320 361 381 536 489 462 393 497]\n",
      "['ring' 'diamond' 'proposed' 'proposing' 'proposal' 'marriage' 'diamonds'\n",
      " 'the' 'planning' 'engagement']\n",
      "[401 106 187 172 196  70 372 150 392 452]\n",
      "['breakup' 'breaking' 'split' 'for' 'of' 'what' 'the' 'break'\n",
      " 'relationship' 'departure']\n",
      "[362 474 339 294 355 487 447 423 360 452]\n",
      "['ring' 'wedding' 'diamond' 'proposed' 'proposal' 'marriage' 'diamonds'\n",
      " 'the' 'planning' 'engagement']\n",
      "[487 152 240 455 266 478 215 106 334 345]\n",
      "['breakup' 'breaking' 'for' 'the' 'of' 'relationship' 'break' 'what'\n",
      " 'with' 'by']\n",
      "[385 268 224 302 301 187 226 290 340 200]\n",
      "['the' 'two' 'of' 'interaction' 'three' 'other' 'next' 'when' 'whether'\n",
      " 'for']\n",
      "[386 225 259  91 270 226 194 383 293 203]\n",
      "['the' 'of' 'first' 'what' 'two' 'next' 'other' 'time' 'when' 'for']\n",
      "[223 137 433 144 311 443 299  83 347 344]\n",
      "['deal' 'business' 'competitor' 'disagreement' 'proposal' 'negotiating'\n",
      " 'initial' 'work' 'amount' 'position']\n",
      "[206 125 219 359 390 339 342 393 279 109]\n",
      "['deal' 'business' 'agreement' 'investment' 'competitor' 'negotiation'\n",
      " 'financial' 'negotiating' 'initial' 'offer']\n",
      "[591 424 350 388 411 540 610 555 422 503]\n",
      "['wedding' 'ring' 'proposed' 'proposing' 'proposal' 'diamonds' 'marriage'\n",
      " 'proposes' 'planning' 'the']\n",
      "[478 275 316 329 377 124 277 232 474 360]\n",
      "['the' 'of' 'first' 'two' 'interaction' 'what' 'next' 'other' 'time'\n",
      " 'when']\n",
      "[388 122 116 181 363 290 166 379 210 103]\n",
      "['breakup' 'breaking' 'splitting' 'for' 'the' 'proposing' 'break'\n",
      " 'relationship' 'of' 'up']\n",
      "[298 271 371 238 377 270 296 385 358  36]\n",
      "['ring' 'diamond' 'rings' 'proposed' 'diamonds' 'proposing' 'planning'\n",
      " 'proposes' 'the' 'upcoming']\n",
      "[245 309 149 270 414 408 392 469 342 364]\n",
      "['deal' 'partnership' 'business' 'agreement' 'acquisition' 'the' 'merger'\n",
      " 'competitor' 'proposal' 'decision']\n"
     ]
    }
   ],
   "source": [
    "for key in all_correls:\n",
    "    this_corr = all_correls[key]\n",
    "    this_corr = np.ravel(this_corr)\n",
    "    story_index = this_corr.argsort()[-10:][::-1]\n",
    "    print(story_index)\n",
    "    # index the top words\n",
    "    top_words = np.zeros((0,1))\n",
    "    for i in range(0, 10):\n",
    "        top_words = np.vstack((top_words, au_words[key][story_index[i]]))\n",
    "    top_words = top_words.ravel()\n",
    "    print(top_words)\n",
    "    top_ten[key]['soc'] = top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Presenting Top Ten Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 11\n",
      "story\n",
      "['hadn' 'could' 'might' 'wasn' 'don' 'can' 'doesn' 'hear' 'got' 'make']\n",
      "loc\n",
      "['restaurant' 'food' 'menus' 'menu' 'diner' 'restuarant' 'foods' 'meal'\n",
      " 'waiter' 'dessert']\n",
      "soc\n",
      "['breakup' 'breaking' 'for' 'of' 'the' 'break' 'relationship' 'what'\n",
      " 'considering' 'ending']\n",
      "\n",
      "\n",
      " 12\n",
      "story\n",
      "['couldn' 'could' 'might' 'didn' 'can' 'don' 'doesn' 'slightly' 'ago'\n",
      " 'should']\n",
      "loc\n",
      "['airport' 'airports' 'plane' 'flight' 'boarding' 'gate' 'gates'\n",
      " 'security' 'departure' 'terminal']\n",
      "soc\n",
      "['breakup' 'breaking' 'split' 'for' 'of' 'what' 'the' 'break'\n",
      " 'relationship' 'departure']\n",
      "\n",
      "\n",
      " 13\n",
      "story\n",
      "['wouldn' 'could' 'might' 'wasn' 'didn' 'don' 'can' 'doesn' 'always'\n",
      " 'nodded']\n",
      "loc\n",
      "['grocery' 'store' 'groceries' 'checkout' 'shopping' 'cashier' 'items'\n",
      " 'cart' 'food' 'products']\n",
      "soc\n",
      "['breakup' 'breaking' 'for' 'the' 'of' 'relationship' 'break' 'what'\n",
      " 'with' 'by']\n",
      "\n",
      "\n",
      " 14\n",
      "story\n",
      "['couldn' 'could' 'don' 'can' 'doesn' 'didn' 'shouldn' 'make' 'sorry'\n",
      " 'hear']\n",
      "loc\n",
      "['lecture' 'class' 'lectures' 'teaching' 'classroom' 'presentation' 'hall'\n",
      " 'semester' 'professor' 'lecturer']\n",
      "soc\n",
      "['breakup' 'breaking' 'splitting' 'for' 'the' 'proposing' 'break'\n",
      " 'relationship' 'of' 'up']\n",
      "\n",
      "\n",
      " 21\n",
      "story\n",
      "['could' 'nodded' 'wasn' 'ago' 'can' 'make' 'always' 'gladly' 'looked'\n",
      " 'got']\n",
      "loc\n",
      "['restaurant' 'food' 'menus' 'menu' 'chef' 'dishes' 'meal' 'waiter'\n",
      " 'dessert' 'eating']\n",
      "soc\n",
      "['ring' 'wedding' 'diamond' 'proposed' 'proposal' 'marriage' 'diamonds'\n",
      " 'the' 'planning' 'engagement']\n",
      "\n",
      "\n",
      " 22\n",
      "story\n",
      "['couldn' 'didn' 'hadn' 'wasn' 'onto' 'got' 'don' 'looked' 'make' 'hear']\n",
      "loc\n",
      "['airport' 'plane' 'flight' 'boarding' 'gate' 'airplane' 'security'\n",
      " 'passenger' 'passengers' 'baggage']\n",
      "soc\n",
      "['wedding' 'ring' 'proposed' 'proposing' 'proposal' 'diamonds' 'marriage'\n",
      " 'proposes' 'planning' 'the']\n",
      "\n",
      "\n",
      " 23\n",
      "story\n",
      "['could' 'didn' 'wasn' 'don' 'got' 'seeing' 'looked' 'cannot' 'knows'\n",
      " 'would']\n",
      "loc\n",
      "['grocery' 'store' 'groceries' 'supermarket' 'checkout' 'shop' 'shopping'\n",
      " 'checkouts' 'grocer' 'shoppers']\n",
      "soc\n",
      "['ring' 'diamond' 'proposed' 'proposing' 'proposal' 'marriage' 'diamonds'\n",
      " 'the' 'planning' 'engagement']\n",
      "\n",
      "\n",
      " 24\n",
      "story\n",
      "['can' 'during' 'ago' 'cannot' 'got' 'extremely' 'towards' 'knows' 'sorry'\n",
      " 'would']\n",
      "loc\n",
      "['lecture' 'class' 'lectures' 'classroom' 'assignment' 'hall' 'lesson'\n",
      " 'semester' 'professor' 'lecturer']\n",
      "soc\n",
      "['ring' 'diamond' 'rings' 'proposed' 'diamonds' 'proposing' 'planning'\n",
      " 'proposes' 'the' 'upcoming']\n",
      "\n",
      "\n",
      " 31\n",
      "story\n",
      "['wouldn' 'could' 'don' 'can' 'make' 'somewhat' 'would' 'knows' 'want'\n",
      " 'looks']\n",
      "loc\n",
      "['restaurant' 'food' 'menus' 'menu' 'restuarant' 'meals' 'meal' 'waiter'\n",
      " 'hotel' 'eating']\n",
      "soc\n",
      "['deal' 'partnership' 'business' 'agreement' 'acquisition' 'the' 'merger'\n",
      " 'competitor' 'proposal' 'decision']\n",
      "\n",
      "\n",
      " 32\n",
      "story\n",
      "['could' 'didn' 'wasn' 'seeing' 'make' 'would' 'isn' 'got' 'amount' 'want']\n",
      "loc\n",
      "['airport' 'plane' 'flight' 'gate' 'gates' 'flights' 'airplane' 'security'\n",
      " 'planes' 'departing']\n",
      "soc\n",
      "['deal' 'business' 'competitor' 'disagreement' 'proposal' 'negotiating'\n",
      " 'initial' 'work' 'amount' 'position']\n",
      "\n",
      "\n",
      " 33\n",
      "story\n",
      "['could' 'doesn' 'wasn' 'can' 'isn' 'should' 'would' 'make' 'extremely'\n",
      " 'knows']\n",
      "loc\n",
      "['grocery' 'store' 'groceries' 'stores' 'supermarket' 'checkout' 'shop'\n",
      " 'checkouts' 'purchase' 'cashier']\n",
      "soc\n",
      "['deal' 'partnership' 'business' 'agreement' 'investment' 'success' 'the'\n",
      " 'handshake' 'deals' 'competitor']\n",
      "\n",
      "\n",
      " 34\n",
      "story\n",
      "['could' 'don' 'can' 'cannot' 'should' 'would' 'during' 'wants' 'amount'\n",
      " 'have']\n",
      "loc\n",
      "['lecture' 'class' 'classes' 'lecturing' 'classroom' 'assignment' 'hall'\n",
      " 'lesson' 'professor' 'of']\n",
      "soc\n",
      "['deal' 'business' 'agreement' 'investment' 'competitor' 'negotiation'\n",
      " 'financial' 'negotiating' 'initial' 'offer']\n",
      "\n",
      "\n",
      " 41\n",
      "story\n",
      "['could' 'might' 'didn' 'seeing' 'laughed' 'got' 'greatly' 'getting'\n",
      " 'would' 'having']\n",
      "loc\n",
      "['restaurant' 'food' 'menus' 'menu' 'dining' 'meals' 'meal' 'waiter'\n",
      " 'cafe' 'sushi']\n",
      "soc\n",
      "['the' 'of' 'first' 'two' 'interaction' 'what' 'next' 'other' 'time'\n",
      " 'when']\n",
      "\n",
      "\n",
      " 42\n",
      "story\n",
      "['could' 'wouldn' 'might' 'hadn' 'slightly' 'can' 'doesn' 'got' 'shouldn'\n",
      " 'make']\n",
      "loc\n",
      "['airport' 'plane' 'flight' 'boarding' 'gate' 'airplane' 'security'\n",
      " 'departure' 'planes' 'destination']\n",
      "soc\n",
      "['the' 'two' 'of' 'interaction' 'three' 'other' 'next' 'when' 'whether'\n",
      " 'for']\n",
      "\n",
      "\n",
      " 43\n",
      "story\n",
      "['could' 'didn' 'sounded' 'got' 'feels' 'looked' 'looks' 'seeing' 'hear'\n",
      " 'would']\n",
      "loc\n",
      "['grocery' 'store' 'groceries' 'supermarket' 'checkout' 'shop' 'shopping'\n",
      " 'warehouse' 'cashier' 'items']\n",
      "soc\n",
      "['the' 'of' 'first' 'what' 'two' 'next' 'other' 'time' 'when' 'for']\n",
      "\n",
      "\n",
      " 44\n",
      "story\n",
      "['couldn' 'could' 'wasn' 'can' 'doesn' 'hasn' 'don' 'seeing' 'looked'\n",
      " 'nodded']\n",
      "loc\n",
      "['lecture' 'class' 'lectures' 'lecturing' 'classroom' 'assignment' 'hall'\n",
      " 'lesson' 'professor' 'lecturer']\n",
      "soc\n",
      "['the' 'two' 'first' 'other' 'what' 'couple' 'of' 'time' 'when' 'next']\n"
     ]
    }
   ],
   "source": [
    "story_order = [11,12,13,14,21,22,23,24,31,32,33,34,41,42,43,44]\n",
    "\n",
    "for story in story_order:\n",
    "    print('\\n\\n',story)\n",
    "    for keys in top_ten[story]:\n",
    "        print(keys)\n",
    "        print(top_ten[story][keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: {'story': array(['hadn', 'could', 'might', 'wasn', 'don', 'can', 'doesn', 'hear',\n",
       "         'got', 'make'], dtype='<U32'),\n",
       "  'loc': array(['restaurant', 'food', 'menus', 'menu', 'diner', 'restuarant',\n",
       "         'foods', 'meal', 'waiter', 'dessert'], dtype='<U32'),\n",
       "  'soc': array(['breakup', 'breaking', 'for', 'of', 'the', 'break', 'relationship',\n",
       "         'what', 'considering', 'ending'], dtype='<U32')},\n",
       " 33: {'story': array(['could', 'doesn', 'wasn', 'can', 'isn', 'should', 'would', 'make',\n",
       "         'extremely', 'knows'], dtype='<U32'),\n",
       "  'loc': array(['grocery', 'store', 'groceries', 'stores', 'supermarket',\n",
       "         'checkout', 'shop', 'checkouts', 'purchase', 'cashier'],\n",
       "        dtype='<U32'),\n",
       "  'soc': array(['deal', 'partnership', 'business', 'agreement', 'investment',\n",
       "         'success', 'the', 'handshake', 'deals', 'competitor'], dtype='<U32')},\n",
       " 44: {'story': array(['couldn', 'could', 'wasn', 'can', 'doesn', 'hasn', 'don', 'seeing',\n",
       "         'looked', 'nodded'], dtype='<U32'),\n",
       "  'loc': array(['lecture', 'class', 'lectures', 'lecturing', 'classroom',\n",
       "         'assignment', 'hall', 'lesson', 'professor', 'lecturer'],\n",
       "        dtype='<U32'),\n",
       "  'soc': array(['the', 'two', 'first', 'other', 'what', 'couple', 'of', 'time',\n",
       "         'when', 'next'], dtype='<U32')},\n",
       " 23: {'story': array(['could', 'didn', 'wasn', 'don', 'got', 'seeing', 'looked',\n",
       "         'cannot', 'knows', 'would'], dtype='<U32'),\n",
       "  'loc': array(['grocery', 'store', 'groceries', 'supermarket', 'checkout', 'shop',\n",
       "         'shopping', 'checkouts', 'grocer', 'shoppers'], dtype='<U32'),\n",
       "  'soc': array(['ring', 'diamond', 'proposed', 'proposing', 'proposal', 'marriage',\n",
       "         'diamonds', 'the', 'planning', 'engagement'], dtype='<U32')},\n",
       " 12: {'story': array(['couldn', 'could', 'might', 'didn', 'can', 'don', 'doesn',\n",
       "         'slightly', 'ago', 'should'], dtype='<U32'),\n",
       "  'loc': array(['airport', 'airports', 'plane', 'flight', 'boarding', 'gate',\n",
       "         'gates', 'security', 'departure', 'terminal'], dtype='<U32'),\n",
       "  'soc': array(['breakup', 'breaking', 'split', 'for', 'of', 'what', 'the',\n",
       "         'break', 'relationship', 'departure'], dtype='<U32')},\n",
       " 21: {'story': array(['could', 'nodded', 'wasn', 'ago', 'can', 'make', 'always',\n",
       "         'gladly', 'looked', 'got'], dtype='<U32'),\n",
       "  'loc': array(['restaurant', 'food', 'menus', 'menu', 'chef', 'dishes', 'meal',\n",
       "         'waiter', 'dessert', 'eating'], dtype='<U32'),\n",
       "  'soc': array(['ring', 'wedding', 'diamond', 'proposed', 'proposal', 'marriage',\n",
       "         'diamonds', 'the', 'planning', 'engagement'], dtype='<U32')},\n",
       " 13: {'story': array(['wouldn', 'could', 'might', 'wasn', 'didn', 'don', 'can', 'doesn',\n",
       "         'always', 'nodded'], dtype='<U32'),\n",
       "  'loc': array(['grocery', 'store', 'groceries', 'checkout', 'shopping', 'cashier',\n",
       "         'items', 'cart', 'food', 'products'], dtype='<U32'),\n",
       "  'soc': array(['breakup', 'breaking', 'for', 'the', 'of', 'relationship', 'break',\n",
       "         'what', 'with', 'by'], dtype='<U32')},\n",
       " 42: {'story': array(['could', 'wouldn', 'might', 'hadn', 'slightly', 'can', 'doesn',\n",
       "         'got', 'shouldn', 'make'], dtype='<U32'),\n",
       "  'loc': array(['airport', 'plane', 'flight', 'boarding', 'gate', 'airplane',\n",
       "         'security', 'departure', 'planes', 'destination'], dtype='<U32'),\n",
       "  'soc': array(['the', 'two', 'of', 'interaction', 'three', 'other', 'next',\n",
       "         'when', 'whether', 'for'], dtype='<U32')},\n",
       " 43: {'story': array(['could', 'didn', 'sounded', 'got', 'feels', 'looked', 'looks',\n",
       "         'seeing', 'hear', 'would'], dtype='<U32'),\n",
       "  'loc': array(['grocery', 'store', 'groceries', 'supermarket', 'checkout', 'shop',\n",
       "         'shopping', 'warehouse', 'cashier', 'items'], dtype='<U32'),\n",
       "  'soc': array(['the', 'of', 'first', 'what', 'two', 'next', 'other', 'time',\n",
       "         'when', 'for'], dtype='<U32')},\n",
       " 32: {'story': array(['could', 'didn', 'wasn', 'seeing', 'make', 'would', 'isn', 'got',\n",
       "         'amount', 'want'], dtype='<U32'),\n",
       "  'loc': array(['airport', 'plane', 'flight', 'gate', 'gates', 'flights',\n",
       "         'airplane', 'security', 'planes', 'departing'], dtype='<U32'),\n",
       "  'soc': array(['deal', 'business', 'competitor', 'disagreement', 'proposal',\n",
       "         'negotiating', 'initial', 'work', 'amount', 'position'],\n",
       "        dtype='<U32')},\n",
       " 34: {'story': array(['could', 'don', 'can', 'cannot', 'should', 'would', 'during',\n",
       "         'wants', 'amount', 'have'], dtype='<U32'),\n",
       "  'loc': array(['lecture', 'class', 'classes', 'lecturing', 'classroom',\n",
       "         'assignment', 'hall', 'lesson', 'professor', 'of'], dtype='<U32'),\n",
       "  'soc': array(['deal', 'business', 'agreement', 'investment', 'competitor',\n",
       "         'negotiation', 'financial', 'negotiating', 'initial', 'offer'],\n",
       "        dtype='<U32')},\n",
       " 22: {'story': array(['couldn', 'didn', 'hadn', 'wasn', 'onto', 'got', 'don', 'looked',\n",
       "         'make', 'hear'], dtype='<U32'),\n",
       "  'loc': array(['airport', 'plane', 'flight', 'boarding', 'gate', 'airplane',\n",
       "         'security', 'passenger', 'passengers', 'baggage'], dtype='<U32'),\n",
       "  'soc': array(['wedding', 'ring', 'proposed', 'proposing', 'proposal', 'diamonds',\n",
       "         'marriage', 'proposes', 'planning', 'the'], dtype='<U32')},\n",
       " 41: {'story': array(['could', 'might', 'didn', 'seeing', 'laughed', 'got', 'greatly',\n",
       "         'getting', 'would', 'having'], dtype='<U32'),\n",
       "  'loc': array(['restaurant', 'food', 'menus', 'menu', 'dining', 'meals', 'meal',\n",
       "         'waiter', 'cafe', 'sushi'], dtype='<U32'),\n",
       "  'soc': array(['the', 'of', 'first', 'two', 'interaction', 'what', 'next',\n",
       "         'other', 'time', 'when'], dtype='<U32')},\n",
       " 14: {'story': array(['couldn', 'could', 'don', 'can', 'doesn', 'didn', 'shouldn',\n",
       "         'make', 'sorry', 'hear'], dtype='<U32'),\n",
       "  'loc': array(['lecture', 'class', 'lectures', 'teaching', 'classroom',\n",
       "         'presentation', 'hall', 'semester', 'professor', 'lecturer'],\n",
       "        dtype='<U32'),\n",
       "  'soc': array(['breakup', 'breaking', 'splitting', 'for', 'the', 'proposing',\n",
       "         'break', 'relationship', 'of', 'up'], dtype='<U32')},\n",
       " 24: {'story': array(['can', 'during', 'ago', 'cannot', 'got', 'extremely', 'towards',\n",
       "         'knows', 'sorry', 'would'], dtype='<U32'),\n",
       "  'loc': array(['lecture', 'class', 'lectures', 'classroom', 'assignment', 'hall',\n",
       "         'lesson', 'semester', 'professor', 'lecturer'], dtype='<U32'),\n",
       "  'soc': array(['ring', 'diamond', 'rings', 'proposed', 'diamonds', 'proposing',\n",
       "         'planning', 'proposes', 'the', 'upcoming'], dtype='<U32')},\n",
       " 31: {'story': array(['wouldn', 'could', 'don', 'can', 'make', 'somewhat', 'would',\n",
       "         'knows', 'want', 'looks'], dtype='<U32'),\n",
       "  'loc': array(['restaurant', 'food', 'menus', 'menu', 'restuarant', 'meals',\n",
       "         'meal', 'waiter', 'hotel', 'eating'], dtype='<U32'),\n",
       "  'soc': array(['deal', 'partnership', 'business', 'agreement', 'acquisition',\n",
       "         'the', 'merger', 'competitor', 'proposal', 'decision'],\n",
       "        dtype='<U32')}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
