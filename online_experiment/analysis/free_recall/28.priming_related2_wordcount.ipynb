{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the word count related to the priming?\n",
    "\n",
    "## based on analysis 22\n",
    "\n",
    "### 2/11/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "from random import randrange\n",
    "from sklearn.metrics import jaccard_score\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.decomposition import PCA #for cluster analysis\n",
    "import matplotlib.pyplot as plt #for plotting\n",
    "import os #for importing\n",
    "import pickle #for loading transcripts\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Pre\n",
    "## A. Importing story and template vectors and sums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = pickle.load( open( 'c_template', \"rb\" ) )\n",
    "mrecalls = pickle.load( open( 'fr_recalls', \"rb\" ) )\n",
    "recalls = pickle.load( open( 'c_recall', \"rb\" ) )\n",
    "stories = pickle.load( open( 'c_stories', \"rb\" ) )\n",
    "ids = pickle.load( open( 'ids_dict', \"rb\" ) )\n",
    "data_dict = pickle.load( open( 'data_dict', \"rb\" ) )\n",
    "# sums\n",
    "sums = pickle.load( open( \"new_sums\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. wordCount function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText preprocessing, based on bittlingmayer/ft_wiki_preproc.py\n",
    "# Remove special characters, put spaces between all tokens\n",
    "SUB = [\"s/’/'/g\", \"s/′/'/g\", \"s/''/ /g\", \"s/'/ ' /g\", 's/“/\"/g', 's/”/\"/g', 's/\"/ /g', \"s/\\\\./ \\\\. /g\", \"s/<br \\\\/>/ /g\", \"s/, / , /g\", \"s/(/ ( /g\", \"s/)/ ) /g\", \"s/\\\\!/ \\\\! /g\", \"s/\\\\?/ \\\\? /g\", \"s/\\\\;/ /g\", \"s/\\\\:/ /g\", \"s/-/ - /g\", \"s/=/ /g\", \"s/=/ /g\", \"s/*/ /g\", \"s/|/ /g\", \"s/«/ /g\", \n",
    "       \"s/…/ /g\", \"s/‘/ /g\", \"s/í/ /g\", \"s/ñ/ /g\", \"s/\\x84/ /g\", \"s/î/ /g\", \"s/ó/ /g\", \"s/\\x83/ /g\", \"s/ï/ /g\", \"s/õ/ /g\",\n",
    "       \"s/ò/ /g\", \"s/,/ /g\", \"s/ô/ /g\", \"s/\\x92/ /g\", \"s/é/ /g\", \"s/\\x8e/ /g\", \"s/â\\x80¦/ /g\", \"s/\\x91/ /g\", \"s/\\x93/ /g\",\n",
    "       \"s/\\x94/ /g\", \"s/ã®/ /g\", \"s/ã¨/ /g\", \"s/ã©/ /g\",\n",
    "       \"s/\\â\\x80\\x99/ /g\", \"s/â\\x80\\x9c/ /g\", \"s/â\\x80\\x9d/ /g\", \"s/â\\x80\\x99/ /g\", \"s/â\\x80\\x9c/ /g\", \"s/â\\x80\\x98/ /g\",\n",
    "       \"s/â/ /g\"]\n",
    "\n",
    "def __normalize_text(s):\n",
    "    for sg in SUB:\n",
    "        rep = sg.replace('\\\\','').split('/')\n",
    "        s = s.replace(rep[1], rep[2])\n",
    "    s = s.replace('/',' ')\n",
    "    return s\n",
    "\n",
    "def __spaces(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def __digits(s):\n",
    "    return ''.join(filter(lambda c: not c.isdigit(), s))\n",
    "\n",
    "# def preproc(s):\n",
    "#     return __punctuation(__spaces(__digits(__normalize_text(s.lower()))))\n",
    "\n",
    "def preproc(s):\n",
    "    return (__spaces(__digits(__normalize_text(s.lower()))))\n",
    "\n",
    "def __punctuation(s):\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "\n",
    "def wordCount(sentence, model = 'fasttext'):        \n",
    "    words = preproc(sentence).split(' ')\n",
    "    \n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the word count for all participants in each priming group\n",
    "### type of output for r: priming, story, wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((0, 3))\n",
    "\n",
    "for story in mrecalls:\n",
    "    for i in range(0, 3):\n",
    "        if i == 0:\n",
    "            prime_type = 'no_prime'\n",
    "        if i == 1:\n",
    "            prime_type = 'loc'\n",
    "        if i == 2:\n",
    "            prime_type = 'soc'\n",
    "        n_partc = mrecalls[story][i].shape[0]\n",
    "        for j in range(0, n_partc):\n",
    "            this_text = mrecalls[story][i][j][0]\n",
    "            wc = wordCount(this_text)\n",
    "            new_row = np.array([prime_type, story, wc])\n",
    "            data = np.vstack((data, new_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('priming_wc.csv', data, delimiter=',', fmt='%s', header='priming,story,wordcount', comments='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
